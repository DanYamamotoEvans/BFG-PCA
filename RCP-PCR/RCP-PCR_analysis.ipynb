{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "swedish-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to analyze data from RCP-PCR experiments.\n",
    "#Run the script in the RCP-PCR directory to analyze test data.\n",
    "#To analyze own data, prepare a directory with name of data under RCP-PCR/Data with uncompressed R1/R2 fastq files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "conscious-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from Bio import SeqIO\n",
    "import operator\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "iraqi-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put directory name under 'Data' with fastq files.\n",
    "dir_name    = 'test'\n",
    "\n",
    "#Tag file\n",
    "tag_file    = 'tag_assignment_test.csv'\n",
    "\n",
    "# Number of threads used to execute commands.\n",
    "threads     = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "modified-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of input fastq files: ['test_R1.fastq', 'test_R2.fastq'] \n",
      "\n",
      " (There should be two files corresponding to R1/R2.)\n"
     ]
    }
   ],
   "source": [
    "#Identify the fastq files to create small fasta files for easier handling.\n",
    "\n",
    "\n",
    "fastq_files = []\n",
    "PATH = os.path.abspath(\".\")\n",
    "lis = os.listdir(\"%s/Data/%s\" % (PATH,dir_name))\n",
    "for f in lis:\n",
    "    if f[-6:] == \".fastq\" :\n",
    "        fastq_files.append(f)\n",
    "print(\"List of input fastq files: %s \\n\\n (There should be two files corresponding to R1/R2.)\"%(fastq_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "divided-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating directries for data proccessing.\n",
    "\n",
    "try:\n",
    "    os.makedirs('%s/Data/%s/fragmented_fasta'%(PATH,dir_name))\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs('%s/Data/%s/blast'%(PATH,dir_name))\n",
    "    os.makedirs('%s/Data/%s/blast/sh.blast'%(PATH,dir_name))\n",
    "    os.makedirs('%s/Data/%s/blast/out.blast'%(PATH,dir_name))\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs('%s/Data/%s/identification'%(PATH,dir_name))\n",
    "    os.makedirs('%s/Data/%s/identification/sh.identification'%(PATH,dir_name))\n",
    "    os.makedirs('%s/Data/%s/identification/out.identification'%(PATH,dir_name))\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs('%s/Data/%s/count'%(PATH,dir_name))\n",
    "    os.makedirs('%s/Data/%s/count/sh.count'%(PATH,dir_name))\n",
    "    os.makedirs('%s/Data/%s/count/out.count'%(PATH,dir_name))\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "suspected-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function to create small fasta files.\n",
    "def make_fasta_from_listoftups(L,name):\n",
    "    with open(\"%s\"%(name),\"w\") as f:\n",
    "        for I in L:\n",
    "            #print I\n",
    "            f.write('>%s\\n'%(str(I[0])))\n",
    "            f.write('%s\\n'%(str(I[1])))\n",
    "        f.close()\n",
    "        print(\"Made fna file : %s\"%(name))\n",
    "\n",
    "def make_fragmented_fasta(F,split_num,read_length,out_dir,dir_name):\n",
    "    line_c  = 0\n",
    "    read_c  = 0\n",
    "    file_count   = 0\n",
    "    with open(F,\"r\") as f:\n",
    "        fasta_tup = []\n",
    "        for line in f:\n",
    "            if (dir_name =='test'):\n",
    "                if line_c < (split_num*4):\n",
    "                    if (line_c % 4 == 0):\n",
    "                        read_ID = line.split(\" \")[0].replace(\":\",\"_\").replace(\"@\",\"\")\n",
    "\n",
    "                    elif (line_c % 4 == 1):\n",
    "                        if read_length > len(line):\n",
    "                            seq = line\n",
    "                        else:\n",
    "                            seq     = line[:read_length]\n",
    "\n",
    "                    elif (line_c % 4 == 3):\n",
    "                        qscore  = line \n",
    "                        fasta_tup.append( (read_ID,seq) )\n",
    "                        read_c +=1\n",
    "\n",
    "                        if (read_c % split_num == 0):\n",
    "                            file_count +=1\n",
    "\n",
    "                            f_name = (\"\").join([F.split(\"/\")[-1].split(\".\")[0] , \"_%d\"%(file_count),\".fna\"])\n",
    "                            out    = (\"/\").join( [out_dir,f_name]) \n",
    "\n",
    "                            make_fasta_from_listoftups(fasta_tup, out )\n",
    "\n",
    "\n",
    "                            fasta_tup = []\n",
    "                    line_c += 1\n",
    "            \n",
    "            else:                \n",
    "                if (line_c % 4 == 0):\n",
    "                    read_ID = line.split(\" \")[0].replace(\":\",\"_\").replace(\"@\",\"\")\n",
    "\n",
    "                elif (line_c % 4 == 1):\n",
    "                    if read_length > len(line):\n",
    "                        seq = line\n",
    "                    else:\n",
    "                        seq     = line[:read_length]\n",
    "\n",
    "                elif (line_c % 4 == 3):\n",
    "                    qscore  = line \n",
    "                    fasta_tup.append( (read_ID,seq) )\n",
    "                    read_c +=1\n",
    "\n",
    "                    if (read_c % split_num == 0):\n",
    "                        file_count +=1\n",
    "\n",
    "                        f_name = (\"\").join([F.split(\"/\")[-1].split(\".\")[0] , \"_%d\"%(file_count),\".fna\"])\n",
    "                        out    = (\"/\").join( [out_dir,f_name]) \n",
    "\n",
    "                        make_fasta_from_listoftups(fasta_tup, out )\n",
    "\n",
    "\n",
    "                        fasta_tup = []\n",
    "                line_c += 1\n",
    "\n",
    "\n",
    "        f.close()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "western-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating directory for fragmented fasta files and executing the function above. \n",
    "for F in fastq_files:\n",
    "     make_fragmented_fasta(\"%s/Data/%s/%s\"%(PATH,dir_name,F),4000000,250,\"%s/Data/%s/fragmented_fasta\"%(PATH,dir_name),dir_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "contemporary-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating BLAST database.\n",
    "os.system(\"makeblastdb -in %s/const-seq.fna -dbtype nucl\"%(PATH))\n",
    "db = '%s/const-seq.fna'%(PATH)\n",
    "\n",
    "# You should be able to see the following output in your terminal \n",
    "#\n",
    "#Building a new DB, current time: 03/09/2021 13:20:38\n",
    "#New DB name:   /Users/username/GitHub/BFG-Y2H/RCP-PCR/const-seq.fna\n",
    "#New DB title:  /Users/username/GitHub/BFG-Y2H/RCP-PCR/const-seq.fna\n",
    "#Sequence type: Nucleotide\n",
    "#Keep MBits: T\n",
    "#Maximum file size: 1000000000B\n",
    "#Adding sequences from FASTA; added 32 sequences in 0.00142884 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "visible-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deefining multi-proccessing handling.\n",
    "def subprocces_sh(core,sh_dir):\n",
    "    command_L = get_sh(sh_dir)\n",
    "    command_L = [\"sh %s/%s\"%(sh_dir,i) for i in command_L]\n",
    "    if core > len(command_L):\n",
    "        core = len(command_L)\n",
    "    n = len(command_L)/core\n",
    "    pool = mp.Pool(core)\n",
    "    feed = {}\n",
    "    for i in range(core):\n",
    "        feed.update({i:[]})\n",
    "    lp = len(command_L)\n",
    "    ky = range(0,lp)\n",
    "    v = 0\n",
    "    for i in range(lp):\n",
    "        feed[v].append(command_L[0])\n",
    "        del command_L[0]\n",
    "        v +=1\n",
    "        if (v==core):\n",
    "            v = 0\n",
    "    fed = []\n",
    "    for i in range(0,core):\n",
    "        fed.append(feed[i])\n",
    "    \n",
    "    results = pool.map(run_sh,fed)\n",
    "    pass\n",
    "\n",
    "def get_sh(x):\n",
    "    files = []\n",
    "    lis = os.listdir(\"%s\" %x)\n",
    "    for i in lis:\n",
    "        if i[-3:] == \".sh\" :\n",
    "            files.append(i)\n",
    "    return files\n",
    "\n",
    "def run_sh(sh_L):\n",
    "    for sh in sh_L:\n",
    "        #print(\"Running command : %s\\n\"%(sh))\n",
    "        os.system(sh)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "geological-liverpool",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_1.sh\n",
      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_2.sh\n"
     ]
    }
   ],
   "source": [
    "# Prepare .sh files for executing BLAST\n",
    "\n",
    "#Listing fragmented fastas files.\n",
    "fasta_files = os.listdir(\"%s/Data/%s/fragmented_fasta\" % (PATH,dir_name)) \n",
    "\n",
    "#Generating sh files.\n",
    "sh = 1\n",
    "for f in fasta_files:\n",
    "    command = \"blastn -task blastn-short -strand plus -db %s/const-seq.fna -outfmt 10 -evalue 1e-3 -query %s/Data/%s/fragmented_fasta/%s -out %s/Data/%s/blast/out.blast/%s.blast\"%(PATH,PATH,dir_name,f,PATH,dir_name,f.split(\".\")[0])\n",
    "    f_name = \"%s/Data/%s/blast/sh.blast/blast_%d.sh\"%(PATH,dir_name,sh)\n",
    "    with open(f_name,\"w\") as F:\n",
    "        F.write(command)\n",
    "        print(\"Generated %s\"%(f_name))\n",
    "    F.close()\n",
    "    sh +=1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "normal-usage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing and executing BLAST.sh files on 2 threads (This will take a while)\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Executing BLAST sh files\n",
    "print(\"Dividing and executing BLAST.sh files on %d threads (This will take a while)\\n\"%(threads))\n",
    "subprocces_sh(threads,\"%s/Data/%s/blast/sh.blast\"%(PATH,dir_name))\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "romance-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading reference files\n",
    "bar2num_file = \"%s/bar2num.txt\"%(PATH)\n",
    "bar_d = {}\n",
    "with open(bar2num_file,\"r\") as F:\n",
    "    for line in F:\n",
    "        cols = line.split(\"\\n\")[0].split(\",\")\n",
    "        num = int(cols[0])  \n",
    "        bar = cols[1]\n",
    "        bar_d[bar] = num\n",
    "    F.close()\n",
    "\n",
    "tag_f    = \"%s/%s\"%(PATH,tag_file)\n",
    "tags = {}\n",
    "with open(tag_f,\"r\") as F:\n",
    "    for line in F:\n",
    "        cols = line.split(\"\\n\")[0].split(\",\")\n",
    "        #AD003,AD,BC,P01-P01\n",
    "        plate        = cols[0]\n",
    "        barcode_type = cols[1] \n",
    "        PCR_type     = cols[2] \n",
    "        tag          = cols[3] \n",
    "        tags[tag] = [plate,barcode_type,PCR_type,tag]\n",
    "    F.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "appropriate-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to parse fasta file to doctionary.\n",
    "def fasta2dict(name):\n",
    "    d = {}\n",
    "    for record in SeqIO.parse(name,\"fasta\"):\n",
    "        d.update({record.id :  str(record.seq)})\n",
    "    return d\n",
    "\n",
    "\n",
    "def remove_key(d, key):\n",
    "    r = dict(d)\n",
    "    del r[key]\n",
    "    return r\n",
    "\n",
    "\n",
    "\n",
    "#Function to parse BLAST output to dictionary\n",
    "def parse_blast_output2dict(blast_R1,blast_R2,PATH,dir_name,tag_f): \n",
    "    # BLAST database sequences in dict format\n",
    "    seq_DB   = fasta2dict(\"%s/const-seq.fna\"%(PATH))\n",
    "    \n",
    "    \n",
    "    blast_d = {}\n",
    "    \n",
    "    with open(blast_R1) as F:\n",
    "        for line in F:\n",
    "            cols           = line.split(\"\\n\")[0].split(\",\")\n",
    "            #print(cols)\n",
    "            read           = cols[0]   \n",
    "            subject        = cols[1]  \n",
    "            str_on_read    = int(cols[6])  \n",
    "            end_on_read    = int(cols[7])\n",
    "            str_on_subject = int(cols[8])\n",
    "            end_on_subject = int(cols[9])\n",
    "            evalue         = float(cols[10])\n",
    "            \n",
    "           \n",
    "            if (str_on_read < end_on_read):\n",
    "                if (str_on_subject ==1):\n",
    "                    if (end_on_subject==len(seq_DB[subject])):\n",
    "                        element = {\"str_on_read\":str_on_read,\n",
    "                                   \"end_on_read\":end_on_read,\n",
    "                                   \"evalue\":evalue}\n",
    "                        try:\n",
    "                            blast_d[read][\"R1\"][subject] = element\n",
    "                        except KeyError:\n",
    "                            try:\n",
    "                                blast_d[read][\"R1\"]       = {}\n",
    "                                blast_d[read][\"R1\"][subject] = element\n",
    "                            except KeyError:\n",
    "                                blast_d[read] = {}\n",
    "                                blast_d[read][\"R1\"]       = {}\n",
    "                                blast_d[read][\"R1\"][subject] = element\n",
    " \n",
    "        F.close()\n",
    "    #pprint(blast_d)  \n",
    "    with open(blast_R2) as F:\n",
    "        for line in F:\n",
    "            cols             = line.split(\"\\n\")[0].split(\",\")\n",
    "            read             = cols[0]  \n",
    "            subject          = cols[1]   \n",
    "            str_on_read      = int(cols[6]   )\n",
    "            end_on_read      = int(cols[7]   )\n",
    "            str_on_subject   = int(cols[8]   )\n",
    "            end_on_subject   = int(cols[9]   )\n",
    "            evalue           = float(cols[10])  \n",
    "    \n",
    "            if (str_on_read < end_on_read):\n",
    "                if (str_on_subject ==1):\n",
    "                    if (end_on_subject==len(seq_DB[subject])):\n",
    "                        \n",
    "                        element = {\"str_on_read\":str_on_read,\n",
    "                                       \"end_on_read\":end_on_read,\n",
    "                                       \"evalue\":evalue}\n",
    "                        try:\n",
    "                            blast_d[read][\"R2\"][subject] = element\n",
    "                        except KeyError:\n",
    "                            try:\n",
    "                                blast_d[read][\"R2\"] = {}\n",
    "                                blast_d[read][\"R2\"][subject] = element\n",
    "                            except KeyError:\n",
    "                                blast_d[read] = {}\n",
    "                                blast_d[read][\"R2\"] = {}\n",
    "                                blast_d[read][\"R2\"][subject] = element\n",
    "\n",
    "        F.close()\n",
    "    \n",
    "        \n",
    "    \n",
    "    return blast_d         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "featured-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign RCP-PCR category and extract index sequences. \n",
    "def assign_category(read_d):\n",
    "\n",
    "    R1 = read_d['R1']\n",
    "    R2 = read_d['R2']\n",
    "    read_R1_seq = read_d['R1']['seq']\n",
    "    read_R2_seq = read_d['R2']['seq']\n",
    "    \n",
    "\n",
    "    # PS1.0 and PS2.0 at the reasonable positions? (end at <40bp)\n",
    "    PS_pos = 0\n",
    "\n",
    "    P_SEQ1 = 0\n",
    "    P_SEQ2 = 0\n",
    "\n",
    "    if( ('PS1.0-primer'in R1.keys()) and ('PS2.0-primer' in R2.keys()) ):\n",
    "        if( (R1['PS1.0-primer']['end_on_read'] < 40) and (R2['PS2.0-primer']['end_on_read'] < 40) ):\n",
    "            P_SEQ1 = read_R1_seq[R1['PS1.0-primer']['str_on_read']-10:R1['PS1.0-primer']['str_on_read']-1]\n",
    "            P_SEQ2 = read_R2_seq[R2['PS2.0-primer']['str_on_read']-10:R2['PS2.0-primer']['str_on_read']-1]\n",
    "            PS_pos = 1\n",
    "            \n",
    "    # Row and Column priming sites from the reasonable positions? (start at <50bp)\n",
    "    # Which category? DB-BC / DB-lox / AD-BC / AD-lox?\n",
    "    DB_BC = 0\n",
    "    DB_lox = 0\n",
    "    AD_BC = 0\n",
    "    AD_lox = 0\n",
    "    \n",
    "    target=0\n",
    "    # Specific category assignment?\n",
    "    category = 0\n",
    "    R_SEQ = 0\n",
    "    C_SEQ = 0\n",
    "    \n",
    "    \n",
    "    if(PS_pos ==1):\n",
    "        R_seq = {}\n",
    "        C_seq = {}\n",
    "        \n",
    "        #DB-BC\n",
    "        if( ('DBU1-primer' in R1.keys()) and ('DBD2-primer' in R2.keys())):\n",
    "            if (R1['PS1.0-primer']['end_on_read'] < R1['DBU1-primer']['str_on_read']):\n",
    "               if (R1['DBU1-primer']['str_on_read'] < 50):\n",
    "                   if (R2['PS2.0-primer']['end_on_read'] < R2['DBD2-primer']['str_on_read']):\n",
    "                        if (R2['DBD2-primer']['str_on_read'] < 50):\n",
    "\n",
    "                            R_seq['DB-BC'] = read_R1_seq[R1['PS1.0-primer']['end_on_read']:R1['DBU1-primer']['str_on_read']+1-2]\n",
    "                            C_seq['DB-BC'] = read_R2_seq[R2['PS2.0-primer']['end_on_read']:R2['DBD2-primer']['str_on_read']+1-2] \n",
    "                            DB_BC = 1\n",
    "                            target+=1\n",
    "\n",
    "               \n",
    "        #DB-lox\n",
    "        if (('DBloxP-primer' in R1.keys()) and ('DBlox2272-primer' in R2.keys())):     \n",
    "            if(R1['PS1.0-primer']['end_on_read'] < R1['DBloxP-primer']['str_on_read']):\n",
    "               if( R1['DBloxP-primer']['str_on_read'] < 50 ):\n",
    "                   if (R2['PS2.0-primer']['end_on_read']< R2['DBlox2272-primer']['str_on_read']):\n",
    "                       if(R2['DBlox2272-primer']['str_on_read'] < 50):\n",
    "               \n",
    "                            R_seq['DB-lox'] = read_R1_seq[R1['PS1.0-primer']['end_on_read']:R1['DBloxP-primer']['str_on_read']+1-2]\n",
    "                            C_seq['DB-lox'] = read_R2_seq[R2['PS2.0-primer']['end_on_read']:R2['DBlox2272-primer']['str_on_read']+1-2] \n",
    "                            DB_lox = 1\n",
    "                            target+=1\n",
    "        #AD-BC\n",
    "        if( ('ADU1-primer' in R1.keys()) and ('ADD2-primer' in R2.keys()) ):\n",
    "            if( (R1['PS1.0-primer']['end_on_read'] < R1['ADU1-primer']['str_on_read'])):\n",
    "               if (R1['ADU1-primer']['str_on_read'] < 50):\n",
    "                   if (R2['PS2.0-primer']['end_on_read'] < R2['ADD2-primer']['str_on_read']):\n",
    "                        if (R2['ADD2-primer']['str_on_read'] < 50):\n",
    "\n",
    "                            R_seq['AD-BC'] = read_R1_seq[R1['PS1.0-primer']['end_on_read']:R1['ADU1-primer']['str_on_read']+1-2]\n",
    "                            C_seq['AD-BC'] = read_R2_seq[R2['PS2.0-primer']['end_on_read']:R2['ADD2-primer']['str_on_read']+1-2] \n",
    "                            AD_BC = 1\n",
    "                            target+=1\n",
    "               \n",
    "        #AD-lox\n",
    "        if ('ADloxP-primer' in R1.keys()) and ('ADlox2272-primer' in R2.keys())  :   \n",
    "            if(R1['PS1.0-primer']['end_on_read'] < R1['ADloxP-primer']['str_on_read']):\n",
    "               if ( R1['ADloxP-primer']['str_on_read'] < 50 ):\n",
    "                   if (R2['PS2.0-primer']['end_on_read']< R2['ADlox2272-primer']['str_on_read']):\n",
    "                       if (R2['ADlox2272-primer']['str_on_read'] < 50):\n",
    "               \n",
    "                            R_seq['AD-lox'] = read_R1_seq[R1['PS1.0-primer']['end_on_read']:R1['ADloxP-primer']['str_on_read']+1-2]\n",
    "                            C_seq['AD-lox'] = read_R2_seq[R2['PS2.0-primer']['end_on_read']:R2['ADlox2272-primer']['str_on_read']+1-2] \n",
    "                            AD_lox = 1\n",
    "                            target+=1\n",
    "\n",
    "       \n",
    "\n",
    "        if(target == 1):\n",
    "            if(DB_BC==1):\n",
    "                category = 'DB-BC'\n",
    "            elif(DB_lox==1):\n",
    "                category = 'DB-lox'\n",
    "            elif(AD_BC==1):\n",
    "                category = 'AD-BC'\n",
    "            elif(AD_lox==1):\n",
    "                category = 'AD-lox'\n",
    "       \n",
    "            R_SEQ = R_seq[category]\n",
    "            C_SEQ = C_seq[category]\n",
    "               \n",
    "        \n",
    "    return (target,category,P_SEQ1,P_SEQ2,R_SEQ,C_SEQ)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "promotional-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining small functions for calling barcode category and tags index.\n",
    "\n",
    "def rv_comp(seq):\n",
    "    bases = {\"A\":\"T\",\"T\":\"A\",\"G\":\"C\",\"C\":\"G\",\"N\":\"N\",\"a\":\"t\",\"t\":\"a\",\"g\":\"c\",\"c\":\"g\",\"n\":\"n\"}\n",
    "    seq_l = list(seq)\n",
    "    rv_comp = [bases[base] for base in seq_l]\n",
    "    rv_comp.reverse()\n",
    "    rv_comp\n",
    "    return (\"\").join(rv_comp)\n",
    "\n",
    "\n",
    "def BC_match(R1,R2):\n",
    "    r1 = R1\n",
    "    r2 = rv_comp(R2) \n",
    "    #print(r1)\n",
    "    #print(r2)\n",
    "    rel = {}\n",
    "    max_match = 0\n",
    "\n",
    "    for i in range(0,len(r1)):\n",
    "        n1 = r1[i]\n",
    "        for j in range(0,len(r2)):\n",
    "            n2 = r2[j]\n",
    "            if(n1 == n2):\n",
    "                diff = j-i\n",
    "                try:\n",
    "                    rel[diff] +=1\n",
    "                    if max_match < rel[diff]:\n",
    "                            max_match       = rel[diff]\n",
    "                            max_match_diff  = diff\n",
    "                except KeyError:\n",
    "                    rel[diff] = 1\n",
    "\n",
    "    BC = []               \n",
    "    \n",
    "    if rel[max_match_diff] >= 18:\n",
    "        diff  = max_match_diff\n",
    "        count = rel[max_match_diff]\n",
    "        r1_bc = r1\n",
    "        r2_bc = r2[diff:]\n",
    "        \n",
    "        for i in range(0,len(r1)):    \n",
    "            nuc_r1 = r1_bc[i]\n",
    "            if (len(r2_bc)-1) > i:\n",
    "                nuc_r2 = r2_bc[i]\n",
    "                if nuc_r1 == nuc_r2:\n",
    "                    n = nuc_r1\n",
    "                elif((nuc_r1==\"N\") and (nuc_r2 != \"N\")):\n",
    "                    n = nuc_r2\n",
    "                elif((nuc_r1!=\"N\") and (nuc_r2 == \"N\")):\n",
    "                    n = nuc_r2\n",
    "                else:\n",
    "                    n = \"N\"\n",
    "            else:\n",
    "                n = nuc_r1\n",
    "            \n",
    "            BC.append(n)\n",
    "    #print((\"\").join(BC))\n",
    "    return (\"\").join(BC)\n",
    "\n",
    "def tag_calling(bar2num,seq):\n",
    "    if len(seq) < 12:\n",
    "        \n",
    "        target_hits = []\n",
    "        for tag in bar2num:\n",
    "            count = {}\n",
    "            for k in range(0,len(tag)):\n",
    "                k_nuc = tag[k]\n",
    "\n",
    "                for i in range(0,len(seq)):\n",
    "                    i_nuc = seq[i]\n",
    "\n",
    "                    rel = k-i\n",
    "                    if(k_nuc == i_nuc):\n",
    "                        try:\n",
    "                            count[rel] += 1\n",
    "                        except KeyError:\n",
    "                            count[rel] = 1\n",
    "                    else:\n",
    "                        try:\n",
    "                            count[rel] += 0\n",
    "                        except KeyError:\n",
    "                            count[rel] = 0\n",
    "            #pprint(count)  \n",
    "            if len(count) > 0:\n",
    "                max_value     = max(count.values()) \n",
    "                max_match_rel = [k for k, v in count.items() if v == max_value] # getting all keys containing the `maximum`\n",
    "                for i in max_match_rel:\n",
    "                    target_hits.append([tag,i,count[i]])\n",
    "                #pprint(target_hits)\n",
    "\n",
    "        target_hits.sort(key=lambda x: x[2],reverse=True)\n",
    "        #pprint(target_hits)\n",
    "        if (len(target_hits) >1):\n",
    "            if(target_hits[0][2] == target_hits[1][2]):\n",
    "                val = 0\n",
    "            elif(target_hits[0][2]>5): \n",
    "                called_bar = bar2num[target_hits[0][0]]\n",
    "                val = called_bar\n",
    "            else:\n",
    "                val = 0\n",
    "        elif(len(target_hits)==1):\n",
    "            #print (target_hits)\n",
    "            if(target_hits[0][2]>5): \n",
    "                called_bar = bar2num[target_hits[0][0]]\n",
    "                val = called_bar\n",
    "        else:\n",
    "            val = 0\n",
    "\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accessory-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definfing function for analysing status of each element within barcode cassette.\n",
    "def analyze_stat(category,R1,R2,seq_DB):\n",
    "    stat = {\"R1\":{},\"R2\":{}}\n",
    "    #print (category)\n",
    "    if (category == \"DB-BC\"):    \n",
    "        # Setting default status \n",
    "        stat[\"R1\"]['DBU1-primer']  = 'there'\n",
    "        stat[\"R1\"]['cDBU2-primer'] = 'absent'\n",
    "        stat[\"R1\"]['UPTAG-frag']   = 'absent'\n",
    "        stat[\"R1\"]['lox2272']      = 'absent'\n",
    "\n",
    "        stat[\"R2\"]['DBD2-primer']  = 'there'\n",
    "        stat[\"R2\"]['cDBD1-primer'] = 'absent'\n",
    "        stat[\"R2\"]['cDNTAG-frag']  = 'absent'\n",
    "\n",
    "\n",
    "        ##### Existence check; UPTAG\n",
    "        if( 'cDBU2-primer' in R1.keys()):\n",
    "            if( R1['DBU1-primer']['end_on_read'] < R1['cDBU2-primer']['str_on_read']):\n",
    "                TAG_str = R1['DBU1-primer']['end_on_read']+1 -1\n",
    "                TAG_end = R1['cDBU2-primer']['str_on_read']-1 -1\n",
    "\n",
    "                stat[\"R1\"]['cDBU2-primer'] = 'there'\n",
    "                stat[\"R1\"]['UPTAG-frag']   =  R1[\"seq\"][TAG_str:TAG_end]\n",
    "\n",
    "\n",
    "\n",
    "        ##### Existence check; lox2272\n",
    "        if('cDBU2-primer'in R1.keys()):\n",
    "            if('lox2272' in R1.keys()):\n",
    "                if(R1['cDBU2-primer']['end_on_read'] < R1['lox2272']['str_on_read']):\n",
    "                    offset = R1['lox2272']['str_on_read'] - R1['cDBU2-primer']['end_on_read'] -1\n",
    "                    stat[\"R1\"]['lox2272'] = 'there;offset=%d'%(offset)\n",
    "\n",
    "        ##### Existence check; DNTAG\n",
    "        if('cDBD1-primer' in R2.keys()):\n",
    "            if(R2['DBD2-primer']['end_on_read'] < R2['cDBD1-primer']['str_on_read']):\n",
    "                TAG_str = R2['DBD2-primer']['end_on_read'] \n",
    "                TAG_end = R2['cDBD1-primer']['str_on_read'] -1\n",
    "\n",
    "                stat[\"R2\"]['cDBD1-primer'] = 'there'\n",
    "                stat[\"R2\"]['cDNTAG-frag']  = R2[\"seq\"][TAG_str:TAG_end]   \n",
    "\n",
    "\n",
    "        ##### Sequence match check\n",
    "        for read in stat:\n",
    "            for primer in stat[read]:\n",
    "                  if primer != \"cDNTAG-frag\":\n",
    "                        if primer != \"UPTAG-frag\":\n",
    "                            s =  stat[read][primer].split(\";\")\n",
    "                            if s[0] == 'there':\n",
    "                                if read ==\"R1\":\n",
    "                                    read_seq = R1['seq'][R1[primer][\"str_on_read\"]:R1[primer][\"end_on_read\"]] \n",
    "                                    if read_seq == seq_DB[primer]:\n",
    "                                        stat[read][primer].replace(\"there\",\"match\")\n",
    "                                    else:\n",
    "                                        stat[read][primer].replace(\"there\",\"no-match\")\n",
    "                                elif(read==\"R2\"):\n",
    "                                    read_seq = R2['seq'][R2[primer][\"str_on_read\"]:R2[primer][\"end_on_read\"]] \n",
    "                                    if read_seq == seq_DB[primer]:\n",
    "                                        stat[read][primer].replace(\"there\",\"match\")\n",
    "                                    else:\n",
    "                                        stat[read][primer].replace(\"there\",\"no-match\")\n",
    "    \n",
    "    elif (category ==\"DB-lox\"):\n",
    "        # Setting default status \n",
    "        stat[\"R1\"]['DBloxP-primer']   = 'there'\n",
    "        stat[\"R1\"]['cloxP']           = 'absent'\n",
    "        stat[\"R1\"]['DBU1-primer']     = 'absent'\n",
    "        stat[\"R1\"]['UPTAG-frag']      = 'absent'                        \n",
    "        stat[\"R1\"]['cDBU2-primer']    = 'absent'\n",
    "\n",
    "        stat[\"R2\"]['DBlox2272-primer']= 'there'\n",
    "        stat[\"R2\"]['clox2272']        = 'absent'\n",
    "        stat[\"R2\"]['DBU2-primer']     = 'absent'\n",
    "        stat[\"R2\"]['cUPTAG-frag']     = 'absent'\n",
    "        stat[\"R2\"]['cDBU1-primer']    = 'absent'\n",
    "        \n",
    "        ##### Existence check; cLoxP\n",
    "        if( 'cloxP' in R1.keys()):\n",
    "            if( R1['DBloxP-primer']['end_on_read'] < R1['cloxP']['str_on_read']):\n",
    "                offset = R1['cloxP']['str_on_read'] - R1['DBloxP-primer']['end_on_read'] -1\n",
    "                stat[\"R1\"]['cloxP'] = 'there;offset=%d'%(offset)\n",
    "\n",
    "        #### Existence check; DBU1-primer\n",
    "        if( 'cloxP' in R1.keys()):\n",
    "            if( 'DBU1-primer' in R1.keys()):    \n",
    "                if( R1['cloxP']['end_on_read'] < R1['DBU1-primer']['str_on_read']):\n",
    "                    offset = R1['DBU1-primer']['str_on_read'] - R1['cloxP']['end_on_read'] -1\n",
    "                    stat[\"R1\"]['DBU1-primer'] = 'there;offset=%d'%(offset)\n",
    "\n",
    "        #### Existence check; cDBU2-primer\n",
    "        if( 'cDBU2-primer' in R1.keys()):\n",
    "            if( 'DBU1-primer' in R1.keys()):    \n",
    "                if( R1['DBU1-primer']['end_on_read'] < R1['cDBU2-primer']['str_on_read']):\n",
    "                    offset = R1['cDBU2-primer']['str_on_read'] - R1['DBU1-primer']['end_on_read'] -1-25\n",
    "                    stat[\"R1\"]['cDBU2-primer'] = 'there;offset=%d'%(offset)\n",
    "\n",
    "                    TAG_str = R1['DBU1-primer']['end_on_read']\n",
    "                    TAG_end = R1['cDBU2-primer']['str_on_read']-1\n",
    "                    stat[\"R1\"]['UPTAG_frag'] = R1[\"seq\"][TAG_str:TAG_end]\n",
    "\n",
    "        ##### Existence check; clox2272\n",
    "        if( 'clox2272' in R1.keys()):\n",
    "            if( R1['cDBlox2272-primer']['end_on_read'] < R1['clox2272']['str_on_read']):\n",
    "                offset = R1['clox2272']['str_on_read'] - R1['DBlox2272-primer']['end_on_read'] -1\n",
    "                stat[\"R1\"]['clox2272'] = 'there;offset=%d'%(offset)\n",
    "\n",
    "        #### Existence check; DBU2-primer\n",
    "        if( 'clox2272' in R2.keys()):\n",
    "            if( 'DBU2-primer' in R2.keys()):    \n",
    "                if( R2['clox2272']['end_on_read'] < R2['DBU2-primer']['str_on_read']):\n",
    "                    offset = R2['DBU2-primer']['str_on_read'] - R2['clox2272']['end_on_read'] -1\n",
    "                    stat[\"R2\"]['DBU2-primer'] = 'there;offset=%d'%(offset)\n",
    "\n",
    "        #### Existence check; cDBU1-primer\n",
    "        if( 'DBU2-primer' in R2.keys()):\n",
    "            if( 'cDBU1-primer' in R2.keys()):    \n",
    "                if( R2['DBU2-primer']['end_on_read'] < R2['cDBU1-primer']['str_on_read']):\n",
    "                    offset = R2['cDBU1-primer']['str_on_read'] - R2['DBU2-primer']['end_on_read'] -1-25\n",
    "                    stat[\"R2\"]['cDBU1-primer'] = 'there;offset=%d'%(offset)\n",
    "\n",
    "                    TAG_str = R2['DBU2-primer']['end_on_read']\n",
    "                    TAG_end = R2['cDBU1-primer']['str_on_read']-1\n",
    "                    stat[\"R2\"]['UPTAG_frag'] = R2[\"seq\"][TAG_str:TAG_end]                       \n",
    "                                \n",
    "\n",
    "        ##### Sequence match check\n",
    "        for read in stat:\n",
    "            for primer in stat[read]:\n",
    "                if primer != \"cUPTAG-frag\":\n",
    "                        if primer != \"UPTAG-frag\":\n",
    "                            s =  stat[read][primer].split(\";\")\n",
    "                            if s[0] == 'there':\n",
    "                                if read ==\"R1\":\n",
    "                                    read_seq = R1['seq'][R1[primer][\"str_on_read\"]:R1[primer][\"end_on_read\"]] \n",
    "                                    if read_seq == seq_DB[primer]:\n",
    "                                        stat[read][primer].replace(\"there\",\"match\")\n",
    "                                    else:\n",
    "                                        stat[read][primer].replace(\"there\",\"no-match\")\n",
    "                                elif(read==\"R2\"):\n",
    "                                    read_seq = R2['seq'][R2[primer][\"str_on_read\"]:R2[primer][\"end_on_read\"]] \n",
    "                                    if read_seq == seq_DB[primer]:\n",
    "                                        stat[read][primer].replace(\"there\",\"match\")\n",
    "                                    else:\n",
    "                                        stat[read][primer].replace(\"there\",\"no-match\")                \n",
    "\n",
    "        #### Fragment match \n",
    "        #pprint(stat)\n",
    "        if stat[\"R1\"][\"UPTAG-frag\"] != \"absent\":\n",
    "            if stat[\"R2\"][\"cUPTAG-frag\"] != \"absent\":\n",
    "                frag  = stat[\"R1\"][\"UPTAG-frag\"]\n",
    "                cfrag = stat[\"R2\"][\"cUPTAG-frag\"]\n",
    "                                \n",
    "                BC    = BC_match(frag,cfrag)\n",
    "                                \n",
    "                stat['merged-UPTAG'] = BC   \n",
    "            else:\n",
    "                stat['merged-UPTAG'] = \"absent\"\n",
    "        else:\n",
    "            stat['merged-UPTAG'] = \"absent\"\n",
    "    \n",
    "    \n",
    "                                \n",
    "    elif (category == \"AD-BC\"):\n",
    "        \n",
    "        # Setting default status \n",
    "        stat[\"R1\"]['ADU1-primer']  = 'there'\n",
    "        stat[\"R1\"]['cADU2-primer'] = 'absent'\n",
    "        stat[\"R1\"]['UPTAG-frag']   = 'absent'\n",
    "        \n",
    "        stat[\"R2\"]['ADD2-primer']  = 'there'\n",
    "        stat[\"R2\"]['cADD1-primer'] = 'absent'\n",
    "        stat[\"R2\"]['cDNTAG-frag']  = 'absent'\n",
    "        stat[\"R2\"]['loxP']         = 'absent'\n",
    "                                \n",
    "\n",
    "\n",
    "        ##### Existence check; UPTAG\n",
    "        if( 'cADU2-primer' in R1.keys()):\n",
    "            if( R1['ADU1-primer']['end_on_read'] < R1['cADU2-primer']['str_on_read']):\n",
    "                TAG_str = R1['ADU1-primer']['end_on_read']\n",
    "                TAG_end = R1['cADU2-primer']['str_on_read']-1\n",
    "\n",
    "                stat[\"R1\"]['cADU2-primer'] = 'there'\n",
    "                stat[\"R1\"]['UPTAG-frag']        =  R1[\"seq\"][TAG_str:TAG_end]\n",
    "\n",
    "\n",
    "\n",
    "        ##### Existence check; loxP\n",
    "        if('cADD1-primer'in R2.keys()):\n",
    "            if('loxP' in  R2.keys()):\n",
    "                if(R2['cADD1-primer']['end_on_read'] < R2['loxP']['str_on_read']):\n",
    "                    offset = R2['loxP']['str_on_read'] - R2['cADD1-primer']['end_on_read'] -1\n",
    "                    stat[\"R2\"]['loxP'] = 'there;offset=%d'%(offset)\n",
    "\n",
    "        ##### Existence check; DNTAG\n",
    "        if('cADD1-primer' in R2.keys()):\n",
    "            if(R2['ADD2-primer']['end_on_read'] < R2['cADD1-primer']['str_on_read']):\n",
    "                TAG_str = R2['ADD2-primer']['end_on_read']\n",
    "                TAG_end = R2['cADD1-primer']['str_on_read']-1\n",
    "\n",
    "                stat[\"R2\"]['cADD1-primer'] = 'there'\n",
    "                stat[\"R2\"]['cDNTAG-frag']  = R2[\"seq\"][TAG_str:TAG_end]   \n",
    "\n",
    "\n",
    "        ##### Sequence match check\n",
    "        #print(stat)\n",
    "        for read in stat:\n",
    "            for primer in stat[read]:\n",
    "                if primer != \"cDNTAG-frag\":\n",
    "                    if primer != \"UPTAG-frag\":\n",
    "                        s =  stat[read][primer].split(\";\")\n",
    "                        if s[0] == 'there':\n",
    "                            if read ==\"R1\":\n",
    "                                read_seq = R1['seq'][R1[primer][\"str_on_read\"]:R1[primer][\"end_on_read\"]] \n",
    "                                if read_seq == seq_DB[primer]:\n",
    "                                    stat[read][primer].replace(\"there\",\"match\")\n",
    "                                else:\n",
    "                                    stat[read][primer].replace(\"there\",\"no-match\")\n",
    "                            elif(read==\"R2\"):\n",
    "                                read_seq = R2['seq'][R2[primer][\"str_on_read\"]:R2[primer][\"end_on_read\"]] \n",
    "                                if read_seq == seq_DB[primer]:\n",
    "                                    stat[read][primer].replace(\"there\",\"match\")\n",
    "                                else:\n",
    "                                    stat[read][primer].replace(\"there\",\"no-match\")\n",
    "\n",
    "    elif (category ==\"AD-lox\"):\n",
    "        #pprint(R1)\n",
    "        #pprint(R2)\n",
    "        # Setting default status \n",
    "        stat[\"R1\"]['ADloxP-primer']   = 'there'\n",
    "        stat[\"R1\"]['cloxP']           = 'absent'\n",
    "        stat[\"R1\"]['ADD1-primer']     = 'absent'\n",
    "        stat[\"R1\"]['DNTAG-frag']      = 'absent'                        \n",
    "        stat[\"R1\"]['cADD2-primer']    = 'absent'\n",
    "\n",
    "        stat[\"R2\"]['ADlox2272-primer']= 'there'\n",
    "        stat[\"R2\"]['clox2272']        = 'absent'\n",
    "        stat[\"R2\"]['ADD2-primer']= 'absent'\n",
    "        stat[\"R2\"]['cDNTAG-frag']= 'absent'\n",
    "        stat[\"R2\"]['cADD1-primer']= 'absent'\n",
    "        #pprint(stat)\n",
    "        ##### Existence check; cLoxP\n",
    "        if( 'cloxP' in R1.keys()):\n",
    "            if( R1['ADloxP-primer']['end_on_read'] < R1['cloxP']['str_on_read']):\n",
    "                offset = R1['cloxP']['str_on_read'] - R1['ADloxP-primer']['end_on_read'] -1\n",
    "                stat[\"R1\"]['cloxP'] = 'there;offset=%d'%(offset)\n",
    "                #print('cloxP')\n",
    "        #### Existence check; ADD1-primer\n",
    "        if( 'cloxP' in R1.keys()):\n",
    "            if( 'ADD1-primer' in R1.keys()):    \n",
    "                if( R1['cloxP']['end_on_read'] < R1['ADD1-primer']['str_on_read']):\n",
    "                    offset = R1['ADD1-primer']['str_on_read'] - R1['cloxP']['end_on_read'] -1\n",
    "                    stat[\"R1\"]['ADD1-primer'] = 'there;offset=%d'%(offset)\n",
    "                    #print('ADD1-primer')\n",
    "\n",
    "        #### Existence check; cADD2-primer\n",
    "        if( 'cADD2-primer' in R1.keys()):\n",
    "            if( 'ADD1-primer' in R1.keys()):    \n",
    "                if( R1['ADD1-primer']['end_on_read'] < R1['cADD2-primer']['str_on_read']):\n",
    "                    offset = R1['cADD2-primer']['str_on_read'] - R1['ADD1-primer']['end_on_read'] -1-25\n",
    "                    stat[\"R1\"]['cADD2-primer'] = 'there;offset=%d'%(offset)\n",
    "\n",
    "                    TAG_str = R1['ADD1-primer']['end_on_read']\n",
    "                    TAG_end = R1['cADD2-primer']['str_on_read']-1\n",
    "                    stat[\"R1\"]['DNTAG-frag'] = R1[\"seq\"][TAG_str:TAG_end]\n",
    "                    #print('cADD2-primer')\n",
    "\n",
    "        ##### Existence check; clox2272\n",
    "        if( 'clox2272' in R2.keys()):\n",
    "            if ('ADlox2272-primer' in R2.keys()):\n",
    "                if( R2['ADlox2272-primer']['end_on_read'] < R2['clox2272']['str_on_read']):\n",
    "                    offset = R2['clox2272']['str_on_read'] - R2['ADlox2272-primer']['end_on_read'] -1\n",
    "                    stat[\"R2\"]['clox2272'] = 'there;offset=%d'%(offset)\n",
    "                    #print('lox2272')\n",
    "        #### Existence check; ADD2-primer\n",
    "        if( 'clox2272' in R2.keys()):\n",
    "            if( 'ADD2-primer' in R2.keys()):    \n",
    "                if( R2['clox2272']['end_on_read'] < R2['ADD2-primer']['str_on_read']):\n",
    "                    offset = R2['ADD2-primer']['str_on_read'] - R2['clox2272']['end_on_read'] -1\n",
    "                    stat[\"R2\"]['ADD2-primer'] = 'there;offset=%d'%(offset)\n",
    "                    #print('ADD2-primer')\n",
    "        #### Existence check; cADD1-primer\n",
    "        if( 'ADD2-primer' in R2.keys()):\n",
    "            if( 'cADD1-primer' in R2.keys()):    \n",
    "                if( R2['ADD2-primer']['end_on_read'] < R2['cADD1-primer']['str_on_read']):\n",
    "                    offset = R2['cADD1-primer']['str_on_read'] - R2['ADD2-primer']['end_on_read'] -1-25\n",
    "                    stat[\"R2\"]['cADD1-primer'] = 'there;offset=%d'%(offset)\n",
    "                    #print('cADD1-primer')\n",
    "                    TAG_str = R2['ADD2-primer']['end_on_read'] \n",
    "                    TAG_end = R2['cADD1-primer']['str_on_read']-1\n",
    "                    stat[\"R2\"]['cDNTAG-frag'] = R2[\"seq\"][TAG_str:TAG_end]                       \n",
    "                    #print('cDNTAG-frag')\n",
    "        #pprint(R1)\n",
    "        #pprint(R2)\n",
    "        #pprint(stat)\n",
    "        ##### Sequence match check\n",
    "        for read in stat:\n",
    "            for primer in stat[read]:\n",
    "                if primer != \"cDNTAG-frag\":\n",
    "                    if primer != \"DNTAG-frag\":\n",
    "                        s =  stat[read][primer].split(\";\")\n",
    "                        if s[0] == 'there':\n",
    "                            if read ==\"R1\":\n",
    "                                read_seq = R1['seq'][R1[primer][\"str_on_read\"]:R1[primer][\"end_on_read\"]] \n",
    "                                if read_seq == seq_DB[primer]:\n",
    "                                    stat[read][primer].replace(\"there\",\"match\")\n",
    "                                else:\n",
    "                                    stat[read][primer].replace(\"there\",\"no-match\")\n",
    "                            elif(read==\"R2\"):\n",
    "                                read_seq = R2['seq'][R2[primer][\"str_on_read\"]:R2[primer][\"end_on_read\"]] \n",
    "                                if read_seq == seq_DB[primer]:\n",
    "                                    stat[read][primer].replace(\"there\",\"match\")\n",
    "                                else:\n",
    "                                    stat[read][primer].replace(\"there\",\"no-match\")\n",
    "                        \n",
    "        #### Fragment match \n",
    "        #pprint(stat)\n",
    "        if stat[\"R1\"][\"DNTAG-frag\"] != \"absent\":\n",
    "            if stat[\"R2\"][\"cDNTAG-frag\"] != \"absent\":\n",
    "                frag  = stat[\"R1\"][\"DNTAG-frag\"]\n",
    "                cfrag = stat[\"R2\"][\"cDNTAG-frag\"]\n",
    "                                \n",
    "                BC    = BC_match(frag,cfrag)\n",
    "                                \n",
    "                stat['merged-DNTAG'] = BC    \n",
    "            else:\n",
    "                stat['merged-DNTAG'] = \"absent\"\n",
    "        else:\n",
    "            stat['merged-DNTAG'] = \"absent\"\n",
    "    R1 = {}\n",
    "    R2 = {}\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-aging",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compatible-thirty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Parsing BLAST output ============\n",
      "Now working on subfiles : test_R1_1.fna & test_R2_1.fna \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77214/77214 [00:48<00:00, 1605.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========         DONE         ============\n",
      "\n",
      "Creating : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/identification/parsed_blast_data_1.pickle\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "seq_DB   = fasta2dict(\"%s/const-seq.fna\"%(PATH))\n",
    "f_pairs = []\n",
    "for f in range(0, len(fasta_files)):\n",
    "    for f2 in range(0, len(fasta_files)):\n",
    "        if \"R1\" in fasta_files[f]:\n",
    "            if fasta_files[f].replace(\"R1\",\"R2\") == fasta_files[f2]:\n",
    "                f_pairs.append([fasta_files[f].split(\".\")[0].split(\"_\")[-1],fasta_files[f],fasta_files[f2]])\n",
    "f_pairs.sort(key=lambda x: x[0])\n",
    "#pprint(f_pairs)\n",
    "print (\"========== Parsing BLAST output ============\")\n",
    "num = 1\n",
    "for small_file in f_pairs:\n",
    "    print (\"Now working on subfiles : %s & %s \"%(small_file[1],small_file[2]))\n",
    "    R1_ID = small_file[1].split(\".\")[0]\n",
    "    R2_ID = small_file[2].split(\".\")[0]\n",
    "\n",
    "    R1_fna = fasta2dict('%s/Data/%s/fragmented_fasta/%s'%(PATH,dir_name,small_file[1]))\n",
    "    R2_fna = fasta2dict('%s/Data/%s/fragmented_fasta/%s'%(PATH,dir_name,small_file[2]))\n",
    "\n",
    "    R1_blast = '%s/Data/%s/blast/out.blast/%s.blast'%(PATH,dir_name,R1_ID)\n",
    "    R2_blast = '%s/Data/%s/blast/out.blast/%s.blast'%(PATH,dir_name,R2_ID)\n",
    "    \n",
    "    #print(R1_ID)\n",
    "    #print(R2_ID)\n",
    "\n",
    "    d = parse_blast_output2dict(R1_blast,R2_blast,PATH,dir_name,tag_f)\n",
    "       \n",
    "    for read in tqdm(d.keys()):\n",
    "        target = 0\n",
    "        try:\n",
    "            d[read][\"R1\"][\"seq\"] = R1_fna[read]\n",
    "            d[read][\"R2\"][\"seq\"] = R2_fna[read]\n",
    "\n",
    "            target,category,P_SEQ1,P_SEQ2,R_SEQ,C_SEQ = assign_category(d[read])\n",
    "            \n",
    "        except KeyError as e:\n",
    "            #print( e)\n",
    "            pass\n",
    "        if target ==1:\n",
    "            #print (\"Read: %s \\n Category:%s\\n Plate tag 1: %s\\n Plate tag 2: %s\\n Row tag: %s\\n Col tag: %s\\n\\n\\n\\n\"%(read,category,P_SEQ1,P_SEQ2,R_SEQ,C_SEQ))\n",
    "\n",
    "            P_TAG1 = \"P%02d\" %(int(tag_calling(bar_d,P_SEQ1)))\n",
    "            P_TAG2 = \"P%02d\" %(int(tag_calling(bar_d,P_SEQ2)))\n",
    "            P_TAGs = \"%s-%s\"%(P_TAG1,P_TAG2)\n",
    "            R_TAG  = \"R%02d\" %(int(tag_calling(bar_d,R_SEQ)))\n",
    "            C_TAG  = \"C%02d\" %(int(tag_calling(bar_d,C_SEQ)))\n",
    "\n",
    "            if int(tag_calling(bar_d,P_SEQ1))*int(tag_calling(bar_d,P_SEQ2))*int(tag_calling(bar_d,R_SEQ))*int(tag_calling(bar_d,C_SEQ))!=0:\n",
    "                #pprint(\"%s\\n%s\\n%s\\n%s\\n%s\"%(read,category,P_TAGs,R_TAG,C_TAG))\n",
    "                #pprint(d[read]['R1'])\n",
    "                #pprint(d[read]['R2'])\n",
    "                stat = analyze_stat(category,d[read]['R1'],d[read]['R2'],seq_DB) \n",
    "                #d = remove_key(d,read)\n",
    "            \n",
    "                #pprint(stat)\n",
    "                try:\n",
    "                    data[category][P_TAGs][R_TAG][C_TAG][read] = stat\n",
    "                except KeyError:\n",
    "                    try:\n",
    "                        data[category][P_TAGs][R_TAG][C_TAG]       = {}\n",
    "                        data[category][P_TAGs][R_TAG][C_TAG][read] = stat\n",
    "                    except KeyError:\n",
    "                        try:\n",
    "                            data[category][P_TAGs][R_TAG]              = {}\n",
    "                            data[category][P_TAGs][R_TAG][C_TAG]       = {}\n",
    "                            data[category][P_TAGs][R_TAG][C_TAG][read] = stat\n",
    "                        except KeyError:\n",
    "                            try:\n",
    "                                data[category][P_TAGs]                     = {}\n",
    "                                data[category][P_TAGs][R_TAG]              = {}\n",
    "                                data[category][P_TAGs][R_TAG][C_TAG]       = {}\n",
    "                                data[category][P_TAGs][R_TAG][C_TAG][read] = stat\n",
    "                            except KeyError:\n",
    "                                data[category]                             = {}\n",
    "                                data[category][P_TAGs]                     = {}\n",
    "                                data[category][P_TAGs][R_TAG]              = {}\n",
    "                                data[category][P_TAGs][R_TAG][C_TAG]       = {}\n",
    "                                data[category][P_TAGs][R_TAG][C_TAG][read] = stat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #pprint(data)\n",
    "    print(\"==========         DONE         ============\\n\\nCreating : %s/Data/%s/identification/parsed_blast_data_%d.pickle\"%(PATH,dir_name,num))\n",
    "    with open(\"%s/Data/%s/identification/parsed_blast_data_%d.pickle\"%(PATH,dir_name,num),'wb') as f:\n",
    "        pickle.dump(data,f)\n",
    "    print(\"Done\")\n",
    "    f.close()\n",
    "    num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "upper-melbourne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB-BC\tP04-P09\tR14\tC02\n",
      "{'M00244_186_000000000-BFK5B_1_1101_16364_1361': {'R1': {'DBU1-primer': 'there',\n",
      "                                                         'UPTAG-frag': 'GGGGTTCTGCCGTAGGGTATCTGT',\n",
      "                                                         'cDBU2-primer': 'there',\n",
      "                                                         'lox2272': 'there;offset=0'},\n",
      "                                                  'R2': {'DBD2-primer': 'there',\n",
      "                                                         'cDBD1-primer': 'there',\n",
      "                                                         'cDNTAG-frag': 'GCTAGGCCTGAGTTCCTGGATTGGA'}},\n",
      " 'M00244_186_000000000-BFK5B_1_1101_18060_4273': {'R1': {'DBU1-primer': 'there',\n",
      "                                                         'UPTAG-frag': 'GTTCCTTCTGTGCAGGACTTCTTT',\n",
      "                                                         'cDBU2-primer': 'there',\n",
      "                                                         'lox2272': 'there;offset=0'},\n",
      "                                                  'R2': {'DBD2-primer': 'there',\n",
      "                                                         'cDBD1-primer': 'there',\n",
      "                                                         'cDNTAG-frag': 'TGATTGTGGGCAGTTAGACGTGGGG'}},\n",
      " 'M00244_186_000000000-BFK5B_1_1101_6006_6367': {'R1': {'DBU1-primer': 'there',\n",
      "                                                        'UPTAG-frag': 'GTTCCTTCTGTGCAGGACTTCTTT',\n",
      "                                                        'cDBU2-primer': 'there',\n",
      "                                                        'lox2272': 'there;offset=0'},\n",
      "                                                 'R2': {'DBD2-primer': 'there',\n",
      "                                                        'cDBD1-primer': 'there',\n",
      "                                                        'cDNTAG-frag': 'TGATTGTGGGCAGTTAGACGTGGGG'}},\n",
      " 'M00244_186_000000000-BFK5B_1_1101_8584_6376': {'R1': {'DBU1-primer': 'there',\n",
      "                                                        'UPTAG-frag': 'CGTGCCTTCTGTTGTGTCGGTTTC',\n",
      "                                                        'cDBU2-primer': 'there',\n",
      "                                                        'lox2272': 'there;offset=0'},\n",
      "                                                 'R2': {'DBD2-primer': 'there',\n",
      "                                                        'cDBD1-primer': 'there',\n",
      "                                                        'cDNTAG-frag': 'CTTGCGGCTCTCTCGTTCATAGGGA'}}}\n",
      "AD-BC\tP04-P02\tR15\tC10\n",
      "{'M00244_186_000000000-BFK5B_1_1101_15313_6461': {'R1': {'ADU1-primer': 'there',\n",
      "                                                         'UPTAG-frag': 'TTCGCTTGTATTCCGGACGTTGCTT',\n",
      "                                                         'cADU2-primer': 'there'},\n",
      "                                                  'R2': {'ADD2-primer': 'there',\n",
      "                                                         'cADD1-primer': 'there',\n",
      "                                                         'cDNTAG-frag': 'TTGCGCTATTTAACGTTAGGATTGT',\n",
      "                                                         'loxP': 'there;offset=0'}},\n",
      " 'M00244_186_000000000-BFK5B_1_1101_15361_1338': {'R1': {'ADU1-primer': 'there',\n",
      "                                                         'UPTAG-frag': 'CATGCTGTTGTTTCGGTCGTGTGCC',\n",
      "                                                         'cADU2-primer': 'there'},\n",
      "                                                  'R2': {'ADD2-primer': 'there',\n",
      "                                                         'cADD1-primer': 'there',\n",
      "                                                         'cDNTAG-frag': 'GGAGGATGGACGGTGGGAGTCTGTG',\n",
      "                                                         'loxP': 'there;offset=0'}}}\n",
      "AD-lox\tP10-P04\tR08\tC06\n",
      "{'M00244_186_000000000-BFK5B_1_1101_16269_1345': {'R1': {'ADD1-primer': 'there;offset=0',\n",
      "                                                         'ADloxP-primer': 'there',\n",
      "                                                         'DNTAG-frag': 'ACAACCGGTCCAGTGACTCCTGGCC',\n",
      "                                                         'cADD2-primer': 'there;offset=0',\n",
      "                                                         'cloxP': 'there;offset=0'},\n",
      "                                                  'R2': {'ADD2-primer': 'there;offset=0',\n",
      "                                                         'ADlox2272-primer': 'there',\n",
      "                                                         'cADD1-primer': 'there;offset=0',\n",
      "                                                         'cDNTAG-frag': 'GGCCAGGAGTCACTGGACCGGTTGT',\n",
      "                                                         'clox2272': 'there;offset=0'},\n",
      "                                                  'merged-DNTAG': 'ACAACCGGTCCAGTGACTCCTGGCC'},\n",
      " 'M00244_186_000000000-BFK5B_1_1101_8740_6725': {'R1': {'ADD1-primer': 'there;offset=0',\n",
      "                                                        'ADloxP-primer': 'there',\n",
      "                                                        'DNTAG-frag': 'ACAACCGGTCCAGTGACTCCTGGCC',\n",
      "                                                        'cADD2-primer': 'there;offset=0',\n",
      "                                                        'cloxP': 'there;offset=0'},\n",
      "                                                 'R2': {'ADD2-primer': 'there;offset=0',\n",
      "                                                        'ADlox2272-primer': 'there',\n",
      "                                                        'cADD1-primer': 'there;offset=0',\n",
      "                                                        'cDNTAG-frag': 'GGCCAGGAGTCACTGGACCGGTTGT',\n",
      "                                                        'clox2272': 'there;offset=0'},\n",
      "                                                 'merged-DNTAG': 'ACAACCGGTCCAGTGACTCCTGGCC'}}\n"
     ]
    }
   ],
   "source": [
    "#This is a pause point.\n",
    "#The following cell can be run without any previous 'heavy' cells.\n",
    "\n",
    "\n",
    "#Glimps at the data\n",
    "with open(\"%s/Data/%s/identification/parsed_blast_data_1.pickle\"%(PATH,dir_name), 'rb') as F:\n",
    "        da = pickle.load(F)\n",
    "#pprint(da)\n",
    "        \n",
    "typs = [\"DB-BC\",\"AD-BC\",\"AD-lox\"]\n",
    "for i in typs:\n",
    "    co = 0\n",
    "    for j in da[i]:\n",
    "        for k in da[i][j]:\n",
    "            for c in da[i][j][k]:\n",
    "                co +=1\n",
    "                if co < 2:\n",
    "                    print(\"%s\\t%s\\t%s\\t%s\"%(i,j,k,c))\n",
    "                    pprint(da[i][j][k][c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "attractive-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the parsed BLAST output, re-organize the data by barcode counts per de-multiplexed sample\n",
    "\n",
    "def get_pickle(x):\n",
    "    files = []\n",
    "    lis = os.listdir(\"%s\" %x)\n",
    "    for i in lis:\n",
    "        if i[-7:] == \".pickle\" :\n",
    "            files.append(i)\n",
    "    files.sort()\n",
    "    return files\n",
    "\n",
    "\n",
    "list_pickle_files = get_pickle(\"%s/Data/%s/identification\"%(PATH,dir_name))\n",
    "\n",
    "count_data = {}\n",
    "\n",
    "for f in list_pickle_files:\n",
    "    with open(\"%s/Data/%s/identification/%s\"%(PATH,dir_name,f), 'rb') as F:\n",
    "        data_in_small_chunk = pickle.load(F)\n",
    "\n",
    "        for rcp in data_in_small_chunk:\n",
    "            for P_TAG in data_in_small_chunk[rcp]:\n",
    "                for R_TAG in data_in_small_chunk[rcp][P_TAG]:\n",
    "                    for C_TAG in data_in_small_chunk[rcp][P_TAG][R_TAG]:\n",
    "                        for read in data_in_small_chunk[rcp][P_TAG][R_TAG][C_TAG]:       \n",
    "                            el_d = {}\n",
    "                            for R in [\"R1\",\"R2\"]:\n",
    "                                for el in data_in_small_chunk[rcp][P_TAG][R_TAG][C_TAG][read][R]:\n",
    "                                    el_d[el] = data_in_small_chunk[rcp][P_TAG][R_TAG][C_TAG][read][R][el]\n",
    "                            #print(rcp)\n",
    "                            #pprint(el_d)\n",
    "                            \n",
    "                            if rcp == \"DB-BC\":\n",
    "                                ####################\n",
    "                                ## DB-BC\n",
    "                                ####################\n",
    "                                UPTAG  = el_d[\"UPTAG-frag\"] \n",
    "                                cDNTAG = el_d[\"cDNTAG-frag\"]\n",
    "                                if cDNTAG != 'absent':\n",
    "                                    DNTAG  = rv_comp(cDNTAG)\n",
    "                                else:\n",
    "                                    DNTAG  = cDNTAG\n",
    "                                BC_pair= \"%s:%s\"%(UPTAG,DNTAG) \n",
    "                              \n",
    "                                els    = ['DBU1-primer','cDBU2-primer','cDBD1-primer','DBD2-primer']                                \n",
    "                                status = (\":\").join([el_d[el] for el in els])                 \n",
    "                                try:\n",
    "                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair][status] += 1\n",
    "                                except KeyError:\n",
    "                                    try:\n",
    "                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair] = {}\n",
    "                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair][status] = 1\n",
    "                                    except KeyError:\n",
    "                                        try:\n",
    "                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair] = {}\n",
    "                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair][status] = 1\n",
    "                                        except KeyError:\n",
    "                                            try:\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG] = {}\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair] = {}\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair][status] = 1\n",
    "\n",
    "                                            except KeyError:\n",
    "                                                try:\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair][status] = 1\n",
    "\n",
    "\n",
    "                                                except KeyError:\n",
    "                                                    try:\n",
    "                                                        count_data[tags[P_TAG][0]] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair][status] = 1\n",
    "\n",
    "                                                    except KeyError:\n",
    "                                                        pass\n",
    "                            if rcp == \"DB-lox\":\n",
    "                                ####################\n",
    "                                ## DB-lox\n",
    "                                ####################\n",
    "                                merged_UPTAG  = data_in_small_chunk[rcp][P_TAG][R_TAG][C_TAG][read][\"merged-UPTAG\"]\n",
    "                                \n",
    "                                els    = ['cloxP','clox2272','DBU1-primer','DBU2-primer']                                \n",
    "                                status = (\":\").join([el_d[el] for el in els])                 \n",
    "                                try:\n",
    "                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_UPTAG][status] += 1\n",
    "                                except KeyError:\n",
    "                                    try:\n",
    "                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_UPTAG] = {}\n",
    "                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_UPTAG][status] = 1\n",
    "                                    except KeyError:\n",
    "                                        try:\n",
    "                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_UPTAG] = {}\n",
    "                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_UPTAG][status] = 1\n",
    "                                        except KeyError:\n",
    "                                            try:\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG] = {}\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_UPTAG] = {}\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_UPTAG][status] = 1\n",
    "\n",
    "                                            except KeyError:\n",
    "                                                try:\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_UPTAG] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_UPTAG][status] = 1\n",
    "\n",
    "\n",
    "                                                except KeyError:\n",
    "                                                    try:\n",
    "                                                        count_data[tags[P_TAG][0]] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_UPTAG] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_UPTAG][status] = 1\n",
    "\n",
    "                                                    except KeyError:\n",
    "                                                        pass\n",
    "                            if rcp == \"AD-BC\":\n",
    "                                ####################\n",
    "                                ## AD-BC\n",
    "                                ####################\n",
    "                                UPTAG  = el_d[\"UPTAG-frag\"] \n",
    "                                cDNTAG = el_d[\"cDNTAG-frag\"]\n",
    "                                if cDNTAG != 'absent':\n",
    "                                    DNTAG  = rv_comp(cDNTAG)\n",
    "                                else:\n",
    "                                    DNTAG  = cDNTAG\n",
    "                                BC_pair= \"%s:%s\"%(UPTAG,DNTAG) \n",
    "\n",
    "                                els    = ['ADU1-primer','cADU2-primer','cADD1-primer','ADD2-primer']                                \n",
    "                                status = (\":\").join([el_d[el] for el in els])                 \n",
    "                                try:\n",
    "                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair][status] += 1\n",
    "                                except KeyError:\n",
    "                                    try:\n",
    "                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair] = {}\n",
    "                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair][status] = 1\n",
    "                                    except KeyError:\n",
    "                                        try:\n",
    "                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair] = {}\n",
    "                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair][status] = 1\n",
    "                                        except KeyError:\n",
    "                                            try:\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG] = {}\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair] = {}\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair][status] = 1\n",
    "\n",
    "                                            except KeyError:\n",
    "                                                try:\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair][status] = 1\n",
    "\n",
    "\n",
    "                                                except KeyError:\n",
    "                                                    try:\n",
    "                                                        count_data[tags[P_TAG][0]] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][BC_pair][status] = 1\n",
    "\n",
    "                                                    except KeyError:\n",
    "                                                        pass\n",
    "                            if rcp == \"AD-lox\":\n",
    "                                ####################\n",
    "                                ## AD-lox\n",
    "                                ####################\n",
    "                                #pprint(data_in_small_chunk[rcp][P_TAG][R_TAG][C_TAG][read])\n",
    "                                try:\n",
    "                                    merged_DNTAG  = data_in_small_chunk[rcp][P_TAG][R_TAG][C_TAG][read][\"merged-DNTAG\"]\n",
    "\n",
    "\n",
    "\n",
    "                                    els    = ['cloxP','clox2272','ADD1-primer','ADD2-primer']                                \n",
    "                                    status = (\":\").join([el_d[el] for el in els])                 \n",
    "                                    try:\n",
    "                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_DNTAG][status] += 1\n",
    "                                    except KeyError:\n",
    "                                        try:\n",
    "                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_DNTAG] = {}\n",
    "                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_DNTAG][status] = 1\n",
    "                                        except KeyError:\n",
    "                                            try:\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_DNTAG] = {}\n",
    "                                                count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_DNTAG][status] = 1\n",
    "                                            except KeyError:\n",
    "                                                try:\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_DNTAG] = {}\n",
    "                                                    count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_DNTAG][status] = 1\n",
    "\n",
    "                                                except KeyError:\n",
    "                                                    try:\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_DNTAG] = {}\n",
    "                                                        count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_DNTAG][status] = 1\n",
    "\n",
    "\n",
    "                                                    except KeyError:\n",
    "                                                        try:\n",
    "                                                            count_data[tags[P_TAG][0]] = {}\n",
    "                                                            count_data[tags[P_TAG][0]][R_TAG] = {}\n",
    "                                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG] = {}\n",
    "                                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp] = {}\n",
    "                                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_DNTAG] = {}\n",
    "                                                            count_data[tags[P_TAG][0]][R_TAG][C_TAG][rcp][merged_DNTAG][status] = 1\n",
    "\n",
    "                                                        except KeyError:\n",
    "                                                            pass\n",
    "                                except KeyError:\n",
    "                                    pass\n",
    "                                    #print (data_in_small_chunk[rcp][P_TAG][R_TAG][C_TAG][read][\"R1\"][\"DNTAG-frag\"])\n",
    "\n",
    "\n",
    "\n",
    "        F.close()\n",
    "#pprint(count_data)\n",
    "        \n",
    "with open(\"%s/Data/%s/count/merged_count_data.pickle\"%(PATH,dir_name),'wb') as f:\n",
    "    pickle.dump(count_data,f)\n",
    "f.close()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "guided-wrist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD006\tR15\tC10\tAD-BC\n",
      "{'CATGCTGTTGTTTCGGTCGTGTGCC:CACAGACTCCCACCGTCCATCCTCC': {'there:there:there:there': 1},\n",
      " 'TTCGCTTGTATTCCGGACGTTGCTT:ACAATCCTAACGTTAAATAGCGCAA': {'there:there:there:there': 1}}\n",
      "AD006\tR15\tC10\tAD-lox\n",
      "{'CAGACTAAACTGGGACTATCAGACT': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 6},\n",
      " 'GGGTAAAGGACCGAGCAAACCGTGG': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 1}}\n",
      "AD006\tR15\tC06\tAD-BC\n",
      "{'TCTGCCTGTTTGGTTCTTTTGTCCG:TTCAAACGTCAACTACCCGACATAG': {'there:there:there:there': 4}}\n",
      "AD006\tR15\tC06\tAD-lox\n",
      "{'ATAACAATAAAGAACAACACAGCGA': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 1},\n",
      " 'CTCTCACCACCTTACACCCACCTTT': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 1},\n",
      " 'TTCAAACGTCAACTACCCGACATAG': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 4}}\n",
      "AD006\tR15\tC21\tAD-BC\n",
      "{'ACGATTCACCTTTCCGTTGCTGGCG:ATAACAATAAAGAACAACACAGCGA': {'there:there:there:there': 1},\n",
      " 'CATGCTGTTGTTTCGGTCGTGTGCC:ATAACAATAAAGAACAACACAGCGA': {'there:there:there:there': 5},\n",
      " 'TATGGTTACGGGTTGCGGCCGGCTG:TAAGACACAATCCACTCATCGGAAC': {'there:there:there:there': 1}}\n",
      "AD006\tR15\tC21\tAD-lox\n",
      "{'ATAACAATAAAGAACAACACAGCGA': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 1},\n",
      " 'GGGCCAGCCTTAGGGGACTAACCAA': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 1},\n",
      " 'TGCAAGACGAATCCTCAAAATAATC': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 1},\n",
      " 'absent': {'there;offset=0:there;offset=0:absent:absent': 1}}\n",
      "AD006\tR15\tC04\tAD-BC\n",
      "{'CGTGATTTTGCTATCTTACTGTTTT:TCCTCGTTTCCCAGCCAAAGGATGG': {'there:there:there:there': 1},\n",
      " 'GCGTTCTGTTCTTGCACGCGCCGTA:ATGCACTTACCCCCGGCATGCTGGT': {'there:there:there:there': 2}}\n",
      "AD006\tR15\tC04\tAD-lox\n",
      "{'ATAACAATAAAGAACAACACAGCGA': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 1},\n",
      " 'CAGCCAGACAGCCCACCCGAATTGC': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 1},\n",
      " 'TTCAAACGTCAACTACCCGACATAG': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 1}}\n",
      "AD006\tR15\tC05\tAD-BC\n",
      "{'TTCGCTTGTATTCCGGACGTTGCTT:CCAAATCGAAAGAAACACAAGCCGT': {'there:there:there:there': 5}}\n",
      "AD006\tR15\tC05\tAD-lox\n",
      "{'AAAACNCTAACANNCGAATAAGCNC': {'there;offset=0:absent:there;offset=0:absent': 1},\n",
      " 'AAGAACCGCGCGTCGCAAGATTCAA': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 1},\n",
      " 'CCAAATCGAAAGAAACACAAGCCGT': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 7},\n",
      " 'TGACGTAGAGTAAGCGAGCACACAT': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 1},\n",
      " 'TGCAAGACGAATCCTCAAAATAATC': {'there;offset=0:there;offset=0:there;offset=0:there;offset=0': 1}}\n"
     ]
    }
   ],
   "source": [
    "#Glimps at the data\n",
    "with open(\"%s/Data/%s/count/merged_count_data.pickle\"%(PATH,dir_name), 'rb') as F:\n",
    "        da = pickle.load(F)\n",
    "co = 0\n",
    "for i in da:\n",
    "    for j in da[i]:\n",
    "        for k in da[i][j]:\n",
    "            for c in da[i][j][k]:\n",
    "                if co < 10:\n",
    "                    print(\"%s\\t%s\\t%s\\t%s\"%(i,j,k,c))\n",
    "                    pprint(da[i][j][k][c])\n",
    "                    co +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "funded-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Functions to call barcode\n",
    "################################################\n",
    "\n",
    "def evaluate(element):\n",
    "\n",
    "    primer_order = ['U1','U2','D1','D2']\n",
    "    lox_order    = ['loxP','lox2272']\n",
    "\n",
    "    if(float(element[\"BC\"]['min_BC_hit_rate_impt']) > 0.1): ##### THINK ABOUT THIS THRESHOLD\n",
    "        try:\n",
    "            primer_array = element[\"BC\"]['likely_stat'].split(\":\") \n",
    "        except KeyError:\n",
    "            primer_array = [\"N_A\",\"N_A\",\"N_A\",\"N_A\"]\n",
    "            \n",
    "        try:\n",
    "            lox_array    = element[\"lox\"]['likely_stat'].split(\":\") \n",
    "        except KeyEror:\n",
    "            lox_array = [\"N_A\",\"N_A\"]\n",
    "        \n",
    "    primer_stat = {}\n",
    "    for i in range(0,4):\n",
    "        if(float(element[\"BC\"]['stat_rate']) > 0.5):\n",
    "            if primer_array[i] == \"match\": #may not be perfect match. Check \n",
    "                primer_stat[primer_order[i]] = '+'\n",
    "        elif(float(element[\"BC\"]['stat_rate']) > 0.5 ):\n",
    "            if primer_array[i] != \"match\":\n",
    "                primer_stat[primer_order[i]] = '-'\n",
    "        else:\n",
    "            primer_stat[primer_order[i]] = 'Ab'\n",
    "\n",
    "    lox_stat = {}\n",
    "    for i in range(0,2):\n",
    "        if(float(element[\"lox\"]['stat_rate']) > 0.5):\n",
    "            if lox_array[i] == \"match\": #may not be perfect match. Check \n",
    "                lox_stat[lox_order[i]] = '+'\n",
    "        elif(float(element[\"lox\"]['stat_rate']) > 0.5 ):\n",
    "            if lox_array[i] != \"match\":\n",
    "                lox_stat[lox_order[i]] = '-'\n",
    "        else:\n",
    "            lox_stat[lox_order[i]] = 'Ab'\n",
    "\n",
    "\n",
    "    evaluated = element\n",
    "    evaluated[\"BC\"]['likely_stat']  = primer_stat\n",
    "    evaluated[\"lox\"]['likely_stat'] = lox_stat\n",
    "\n",
    "    return evaluated\n",
    "\n",
    "def match(barcode_i,barcode_j):\n",
    "    match_d = {}\n",
    "    barcode_i_nuc = barcode_i.replace(\":\",\"\")\n",
    "    barcode_j_nuc = barcode_j.replace(\":\",\"\")\n",
    "    min_len = min(len(barcode_i_nuc),len(barcode_j_nuc))\n",
    "\n",
    "    num = 0\n",
    "    for n in range(min_len):\n",
    "        ni = barcode_i_nuc[n]\n",
    "        nj = barcode_j_nuc[n]\n",
    "        if (ni ==nj):\n",
    "            num+=1\n",
    "\n",
    "            \n",
    "    match_d['num'] = num\n",
    "    match_d['rate']= float(num)/min_len\n",
    "    \n",
    "    return match_d\n",
    "\n",
    "def ErrorProp_div(Hit,All):\n",
    "    val = 0\n",
    "    error = 0\n",
    "\n",
    "    Hit = float(Hit)\n",
    "    All = float(All)\n",
    "\n",
    "\n",
    "    val = Hit/All\n",
    "    d_All = All **(0.5)\n",
    "    #print All,d_All\n",
    "    d_Hit = Hit **(0.5)\n",
    "    #print target, d_target\n",
    "    error = ((d_All/All) ** 2) + ((d_Hit/Hit) ** 2)\n",
    "    error **= 0.5\n",
    "    error  *= val\n",
    "\n",
    "    return (val,error)\n",
    "\n",
    "\n",
    "def cal_rate(count_all):\n",
    "    BC_all  = count_all['BC_all']\n",
    "    lox_all = count_all['lox_all']\n",
    "\n",
    "    data = count_all[\"Data\"]\n",
    "    #pprint(count_all)\n",
    "    \n",
    "   \n",
    "    \n",
    "    for barcode in data:\n",
    "        #print(barcode)\n",
    "        BC_hit_rate, BC_hit_rate_error = ErrorProp_div(data[barcode]['BC']['hit'], BC_all)\n",
    "        min_BC_hit_rate   = BC_hit_rate   - BC_hit_rate_error\n",
    "\n",
    "        data[barcode]['BC']['min_BC_hit_rate_impt'] = \"%.4f\"%(min_BC_hit_rate)\n",
    "\n",
    "        BC_stat_rate, BC_stat_rate_error  = ErrorProp_div(data[barcode]['BC']['likely_stat_count'],data[barcode]['BC']['hit'])\n",
    "        try:\n",
    "            lox_stat_rate,lox_stat_rate_error = ErrorProp_div(data[barcode]['lox']['likely_stat_count'],data[barcode]['lox']['hit'])\n",
    "        except ZeroDivisionError:\n",
    "            lox_stat_rate = 0\n",
    "            lox_stat_rate_error = 0\n",
    "        \n",
    "\n",
    "        min_BC_stat_rate  = \"%.4f\"%float(BC_stat_rate  - BC_stat_rate_error)\n",
    "        min_lox_stat_rate = \"%.4f\"%float(lox_stat_rate - lox_stat_rate_error)\n",
    "        data[barcode]['BC']['stat_rate']  = \"%.4f\"%float(min_BC_stat_rate)\n",
    "        data[barcode]['lox']['stat_rate'] = \"%.4f\"%float(min_lox_stat_rate)\n",
    "\n",
    "        count_all['Data'] = data\n",
    "  \n",
    "    return count_all\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def call_barcode(data,ad_db):\n",
    "    count_all = {\"BC_all\":0,\"lox_all\":0,\"Data\":{}}\n",
    "    BC_all  = 0\n",
    "    lox_all = 0\n",
    "        \n",
    "    pas = 0\n",
    "    ####################################\n",
    "    # Count useful BC tag and its stat #\n",
    "    ####################################\n",
    "    pattern = '^[ATGCN]+\\:[ATGCN]+'\n",
    "    count_array = []\n",
    "    #pprint(data)\n",
    "    for barcode in data[\"%s-BC\"%(ad_db)]:\n",
    "        if re.match(pattern,barcode):\n",
    "            counts      = {}\n",
    "            counts['barcode']         = barcode\n",
    "            pas = 1\n",
    "            element                 = data[\"%s-BC\"%(ad_db)][barcode] \n",
    "            for stat in element:\n",
    "                BC_all                    += element[stat]\n",
    "                try:\n",
    "                    \n",
    "                    counts['count']['All']   += element[stat]    \n",
    "                    counts['count'][stat]     = element[stat]\n",
    "                except KeyError:\n",
    "                    counts['count']           = {}\n",
    "                    counts['count']['All']    = element[stat]    \n",
    "                    counts['count'][stat]     = element[stat]\n",
    "\n",
    "                        \n",
    "                    \n",
    "            count_array.append(counts)\n",
    "        \n",
    "    if pas ==1:\n",
    "        #pprint(count_array)\n",
    "        count_array = [[count['barcode'],count['count']['All'],count['count']] for count in count_array ]\n",
    "        \n",
    "        count_array.sort(key=lambda x: x[1],reverse=True)\n",
    "        #pprint(count_array)\n",
    "       \n",
    "\n",
    "\n",
    "    #######################################\n",
    "    # Count useful lox reads and its stat #\n",
    "    #######################################\n",
    "    pas2 = 0\n",
    "    pattern = '^[ATGCN]+'\n",
    "    for barcode in data[\"%s-lox\"%(ad_db)]:\n",
    "        if re.match(pattern,barcode):\n",
    "            pas2 =1\n",
    "            element                 = data[\"%s-lox\"%(ad_db)][barcode] \n",
    "            for stat in element:\n",
    "                    lox_all        += element[stat]\n",
    "    \n",
    "    count_all[\"BC_all\"]  = BC_all\n",
    "    count_all[\"lox_all\"] = lox_all\n",
    "    \n",
    "   \n",
    "    if (pas * pas2)==1:\n",
    "\n",
    "        ########################\n",
    "        ##### impute counts of similar barcodes \n",
    "        ########################\n",
    "        if len(count_array) > 1:\n",
    "            for i in range(len(count_array)):\n",
    "                for j in range(1,len(count_array)-i):\n",
    "                    J = j + i\n",
    "\n",
    "                    barcode_i = count_array[i][0]\n",
    "                    barcode_j = count_array[J][0]\n",
    "\n",
    "                    all_i     = count_array[i][1]\n",
    "                    all_j     = count_array[J][1]\n",
    "\n",
    "\n",
    "                    if all_i > all_j:\n",
    "                        match_d = match(barcode_i,barcode_j)\n",
    "                        if match_d['rate'] > 0.8:\n",
    "                            for stat in count_array[J][2]:\n",
    "                                #print(stat)\n",
    "                                try:\n",
    "                                    count_array[i][2][stat] += count_array[J][2][stat]\n",
    "                                except KeyError:\n",
    "                                    count_array[i][2][stat] = count_array[J][2][stat] \n",
    "                                count_array[J][2][stat] = 0\n",
    "                            count_array[J][1] = 0\n",
    "                        \n",
    "\n",
    "        ####################\n",
    "        # Removing queries with no reads\n",
    "        \n",
    "        #pprint(count_array)            \n",
    "        count_array.sort(key=lambda x: x[1],reverse=True)\n",
    "        count_array = [i for i in count_array if i[1]>0]\n",
    "        #pprint(count_array)            \n",
    "        \n",
    "        \n",
    "        ##############################################\n",
    "        ## Examining stat of Lox data for the same barcode\n",
    "        \n",
    "        \n",
    "        #pprint(data[\"%s-lox\"%(ad_db)])\n",
    "        for bar in count_array:\n",
    "            lox = {'count':{'All':0}}\n",
    "            UPTAG = bar[0].split(\":\")[0]\n",
    "            DNTAG = bar[0].split(\":\")[1]\n",
    "            if ad_db ==\"DB\":\n",
    "                TAG = UPTAG\n",
    "                lox['count'][TAG]= {'All':0}\n",
    "            if ad_db ==\"AD\":\n",
    "                TAG = DNTAG\n",
    "                lox['count'][TAG]= {'All':0}\n",
    "        \n",
    "            for lox_barcode in data[\"%s-lox\"%(ad_db)]:\n",
    "                pattern = '^[ATGCN]+'\n",
    "                #pprint(lox_barcode)\n",
    "                if re.match(pattern,lox_barcode):\n",
    "                    if ad_db ==\"DB\":\n",
    "                        match_d = match(UPTAG,lox_barcode)\n",
    "                    if ad_db ==\"AD\":\n",
    "                        match_d = match(DNTAG,lox_barcode)\n",
    "                    \n",
    "                    for stat in data[\"%s-lox\"%(ad_db)][lox_barcode]:\n",
    "                        #print(lox_barcode), print(stat),print(data[\"%s-lox\"%(ad_db)][lox_barcode][stat])\n",
    "                        lox['count']['All'] += data[\"%s-lox\"%(ad_db)][lox_barcode][stat]\n",
    "                        if match_d['rate'] > 0.8:\n",
    "                            lox['count'][TAG]['All'] += data[\"%s-lox\"%(ad_db)][lox_barcode][stat]\n",
    "                            try:\n",
    "                                lox['count'][TAG][stat]  += data[\"%s-lox\"%(ad_db)][lox_barcode][stat]\n",
    "                            except KeyError:\n",
    "                                lox['count'][TAG][stat]   = data[\"%s-lox\"%(ad_db)][lox_barcode][stat]\n",
    "            #################\n",
    "            ## Likely status of BC and Lox \n",
    "\n",
    "            BC_stat = [] \n",
    "            likely_BC_stat = 'absent'\n",
    "            likely_BC_stat_count = 0\n",
    "            for stat in bar[2]:  \n",
    "                if (stat != 'All'):\n",
    "                    BC_stat.append([stat,bar[2][stat]])   \n",
    "                    BC_stat.sort(key=lambda x: x[1],reverse=True)\n",
    "                    #pprint(BC_stat)\n",
    "\n",
    "                    likely_BC_stat       = BC_stat[0][0]\n",
    "                    likely_BC_stat_count += BC_stat[0][1]\n",
    "\n",
    "            lox_stat = [] \n",
    "            #pprint(lox)\n",
    "            likely_lox_stat       = 'absent'\n",
    "            likely_lox_stat_count = 0\n",
    "\n",
    "            for stat in lox['count'][TAG]:\n",
    "                if (stat != 'All'):\n",
    "                    lox_stat.append([stat,lox['count'][TAG][stat]])   \n",
    "\n",
    "                    lox_stat.sort(key=lambda x: x[1],reverse=True)\n",
    "                    #pprint(lox_stat)\n",
    "                    likely_lox_stat       = lox_stat[0][0]\n",
    "                    likely_lox_stat_count += lox_stat[0][1]\n",
    "\n",
    "\n",
    "            #################################\n",
    "            ## Data for screening good wells\n",
    "\n",
    "\n",
    "            count_strct = {\"BC\":{},\"lox\":{}}\n",
    "\n",
    "            count_strct[\"BC\"][\"UPTAG\"]              = UPTAG\n",
    "            count_strct[\"BC\"][\"DNTAG\"]              = DNTAG\n",
    "            count_strct[\"BC\"][\"hit\"]                = bar[2]['All']\n",
    "            count_strct[\"BC\"][\"likely_stat\"]        = likely_BC_stat\n",
    "            count_strct[\"BC\"][\"likely_stat_count\"]  = likely_BC_stat_count\n",
    "            count_strct[\"lox\"][\"hit\"]               = lox['count'][TAG]['All']\n",
    "            count_strct[\"lox\"][\"likely_stat\"]       = likely_lox_stat\n",
    "            count_strct[\"lox\"][\"likely_stat_count\"] = likely_lox_stat_count\n",
    "\n",
    "            count_all[\"Data\"][bar[0]] = count_strct\n",
    "        \n",
    "        \n",
    "        #pprint(count_all)\n",
    "\n",
    "        rate_strct = cal_rate(count_all)\n",
    "\n",
    "        return rate_strct\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "interpreted-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BC_all': 9,\n",
      " 'Data': {'ATCGTTTTTTGGTTTCAGTCCTGTA:CATTTAGGATAGAGCCACACTGAAA': {'BC': {'DNTAG': 'CATTTAGGATAGAGCCACACTGAAA',\n",
      "                                                                         'UPTAG': 'ATCGTTTTTTGGTTTCAGTCCTGTA',\n",
      "                                                                         'hit': 1,\n",
      "                                                                         'likely_stat': 'there:there:there:there',\n",
      "                                                                         'likely_stat_count': 1,\n",
      "                                                                         'min_BC_hit_rate_impt': '-0.0060',\n",
      "                                                                         'stat_rate': '-0.4142'},\n",
      "                                                                  'lox': {'hit': 0,\n",
      "                                                                          'likely_stat': 'absent',\n",
      "                                                                          'likely_stat_count': 0,\n",
      "                                                                          'stat_rate': '0.0000'}},\n",
      "          'CTGAGCTGTGGGCCCTTCTCCCTGT:GGAGCTTAGGGCTCCGATCACCCTT': {'BC': {'DNTAG': 'GGAGCTTAGGGCTCCGATCACCCTT',\n",
      "                                                                         'UPTAG': 'CTGAGCTGTGGGCCCTTCTCCCTGT',\n",
      "                                                                         'hit': 7,\n",
      "                                                                         'likely_stat': 'there:there:there:there',\n",
      "                                                                         'likely_stat_count': 7,\n",
      "                                                                         'min_BC_hit_rate_impt': '0.3858',\n",
      "                                                                         'stat_rate': '0.4655'},\n",
      "                                                                  'lox': {'hit': 2,\n",
      "                                                                          'likely_stat': 'there;offset=0:there;offset=0:there;offset=0:there;offset=0',\n",
      "                                                                          'likely_stat_count': 2,\n",
      "                                                                          'stat_rate': '0.0000'}},\n",
      "          'TGCTGTGGTCGTATCATGTGCGGTT:GGAGCTTAGGGCTCCGATCACCCTT': {'BC': {'DNTAG': 'GGAGCTTAGGGCTCCGATCACCCTT',\n",
      "                                                                         'UPTAG': 'TGCTGTGGTCGTATCATGTGCGGTT',\n",
      "                                                                         'hit': 1,\n",
      "                                                                         'likely_stat': 'there:there:there:there',\n",
      "                                                                         'likely_stat_count': 1,\n",
      "                                                                         'min_BC_hit_rate_impt': '-0.0060',\n",
      "                                                                         'stat_rate': '-0.4142'},\n",
      "                                                                  'lox': {'hit': 2,\n",
      "                                                                          'likely_stat': 'there;offset=0:there;offset=0:there;offset=0:there;offset=0',\n",
      "                                                                          'likely_stat_count': 2,\n",
      "                                                                          'stat_rate': '0.0000'}}},\n",
      " 'lox_all': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor plate in count_data:\\n    typ = plate[:2]\\n    for R in count_data[plate]:\\n        for C in count_data[plate][R]:\\n            #print(plate,R,C)\\n            #pprint(count_data[plate][R][C])\\n            if \"%s-BC\"%(typ) in count_data[plate][R][C]: \\n                if \"%s-lox\"%(typ) in count_data[plate][R][C]:\\n                    count_data[plate][R][C] = call_barcode(count_data[plate][R][C],typ)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"%s/Data/%s/count/merged_count_data.pickle\"%(PATH,dir_name), 'rb') as F:\n",
    "    count_data = pickle.load(F)\n",
    "    F.close()\n",
    "#pprint(count_data)\n",
    "\n",
    "evaluated = {}\n",
    "count_data2 = call_barcode(count_data[\"AD003\"][\"R01\"][\"C04\"],\"AD\")\n",
    "pprint(count_data2)\n",
    "for bc in count_data2['Data']:\n",
    "    ev = evaluate(count_data2['Data'][bc])\n",
    "\"\"\"\n",
    "for plate in count_data:\n",
    "    typ = plate[:2]\n",
    "    for R in count_data[plate]:\n",
    "        for C in count_data[plate][R]:\n",
    "            #print(plate,R,C)\n",
    "            #pprint(count_data[plate][R][C])\n",
    "            if \"%s-BC\"%(typ) in count_data[plate][R][C]: \n",
    "                if \"%s-lox\"%(typ) in count_data[plate][R][C]:\n",
    "                    count_data[plate][R][C] = call_barcode(count_data[plate][R][C],typ)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-syndication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare test data from reads in MiSeq10-26-2017 out.identification files\n",
    "# Vidualizing the output\n",
    "\n",
    "\n",
    "#show\n",
    "#from wand.image import Image as WImage\n",
    "#img = WImage(filename='hat.pdf')\n",
    "#img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#Montecarlo simulation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
