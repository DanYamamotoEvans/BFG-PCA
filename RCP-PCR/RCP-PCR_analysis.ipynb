{

 "cells": [

  {

   "cell_type": "code",

   "execution_count": 43,

   "id": "swedish-poverty",

   "metadata": {},

   "outputs": [],

   "source": [

    "#Script to analyze data from RCP-PCR experiments.\n",

    "#Run the script in the RCP-PCR directory to analyze test data.\n",

    "#To analyze own data, prepare a directory with name of data under RCP-PCR/Data with uncompressed R1/R2 fastq files."

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 44,

   "id": "conscious-scoop",

   "metadata": {},

   "outputs": [],

   "source": [

    "import os \n",

    "import sys\n",

    "import numpy as np\n",

    "import multiprocessing as mp\n",

    "from Bio import SeqIO\n",

    "import operator\n",

    "from pprint import pprint"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 45,

   "id": "iraqi-portland",

   "metadata": {},

   "outputs": [],

   "source": [

    "# Put directory name under 'Data' with fastq files.\n",

    "dir_name    = 'test'\n",

    "\n",

    "#Tag file\n",

    "tag_file    = 'tag_assignment_test.csv'\n",

    "\n",

    "# Number of threads used to execute commands.\n",

    "threads     = 2"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 46,

   "id": "modified-qualification",

   "metadata": {},

   "outputs": [

    {

     "name": "stdout",

     "output_type": "stream",

     "text": [

      "List of input fastq files: ['test_R1.fastq', 'test_R2.fastq'] \n",

      "\n",

      " (There should be two files corresponding to R1/R2.)\n"

     ]

    }

   ],

   "source": [

    "#Identify the fastq files to create small fasta files for easier handling.\n",

    "\n",

    "\n",

    "fastq_files = []\n",

    "PATH = os.path.abspath(\".\")\n",

    "lis = os.listdir(\"%s/Data/%s\" % (PATH,dir_name))\n",

    "for f in lis:\n",

    "    if f[-6:] == \".fastq\" :\n",

    "        fastq_files.append(f)\n",

    "print(\"List of input fastq files: %s \\n\\n (There should be two files corresponding to R1/R2.)\"%(fastq_files))\n"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 47,

   "id": "divided-matthew",

   "metadata": {},

   "outputs": [],

   "source": [

    "#Creating directries for data proccessing.\n",

    "\n",

    "try:\n",

    "    os.makedirs('%s/Data/%s/fragmented_fasta'%(PATH,dir_name))\n",

    "except OSError:\n",

    "    pass\n",

    "\n",

    "try:\n",

    "    os.makedirs('%s/Data/%s/blast'%(PATH,dir_name))\n",

    "    os.makedirs('%s/Data/%s/blast/sh.blast'%(PATH,dir_name))\n",

    "    os.makedirs('%s/Data/%s/blast/out.blast'%(PATH,dir_name))\n",

    "except OSError:\n",

    "    pass\n",

    "\n",

    "try:\n",

    "    os.makedirs('%s/Data/%s/identification'%(PATH,dir_name))\n",

    "    os.makedirs('%s/Data/%s/identification/sh.identification'%(PATH,dir_name))\n",

    "    os.makedirs('%s/Data/%s/identification/out.identification'%(PATH,dir_name))\n",

    "except OSError:\n",

    "    pass\n",

    "\n",

    "try:\n",

    "    os.makedirs('%s/Data/%s/count'%(PATH,dir_name))\n",

    "    os.makedirs('%s/Data/%s/count/sh.count'%(PATH,dir_name))\n",

    "    os.makedirs('%s/Data/%s/count/out.count'%(PATH,dir_name))\n",

    "except OSError:\n",

    "    pass"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 48,

   "id": "suspected-template",

   "metadata": {},

   "outputs": [],

   "source": [

    "#Defining function to create small fasta files.\n",

    "def make_fasta_from_listoftups(L,name):\n",

    "    with open(\"%s\"%name,\"w\") as f:\n",

    "        for I in L:\n",

    "            #print I\n",

    "            f.write('>%s'%(str(I[0])))\n",

    "            f.write('%s\\n'%(str(I[1])))\n",

    "        f.close()\n",

    "        print(\"Made fna file : %s\"%(name))\n",

    "\n",

    "def make_fragmented_fasta(F,split_num,read_length,out_dir):\n",

    "    line_c  = 0\n",

    "    read_c  = 0\n",

    "    file_count   = 0\n",

    "    with open(F,\"r\") as f:\n",

    "        fasta_tup = []\n",

    "        for line in f:\n",

    "            #print(line)\n",

    "            if (line_c % 4 == 0):\n",

    "                read_ID = line.replace(\" \",\"_\").replace(\":\",\"_\").replace(\"@\",\"\")\n",

    "\n",

    "            elif (line_c % 4 == 1):\n",

    "                if read_length > len(line):\n",

    "                    seq = line\n",

    "                else:\n",

    "                    seq     = line[:read_length]\n",

    "\n",

    "            elif (line_c % 4 == 3):\n",

    "                qscore  = line \n",

    "                fasta_tup.append( (read_ID,seq) )\n",

    "                read_c +=1\n",

    "                \n",

    "                if (read_c % split_num == 0):\n",

    "                    file_count +=1\n",

    "                    \n",

    "                    f_name = (\"\").join([F.split(\"/\")[-1].split(\".\")[0] , \"_%d\"%(file_count),\".fna\"])\n",

    "                    out    = (\"/\").join( [out_dir,f_name]) \n",

    "\n",

    "                    make_fasta_from_listoftups(fasta_tup, out )\n",

    "                    \n",

    "                    fasta_tup = []\n",

    "            line_c += 1\n",

    "        f.close()\n",

    "    pass"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 49,

   "id": "western-constitutional",

   "metadata": {},

   "outputs": [

    {

     "name": "stdout",

     "output_type": "stream",

     "text": [

      "Made fna file : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/fragmented_fasta/test_R1_1.fna\n",

      "Made fna file : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/fragmented_fasta/test_R1_2.fna\n",

      "Made fna file : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/fragmented_fasta/test_R1_3.fna\n",

      "Made fna file : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/fragmented_fasta/test_R1_4.fna\n",

      "Made fna file : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/fragmented_fasta/test_R1_5.fna\n",

      "Made fna file : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/fragmented_fasta/test_R1_6.fna\n",

      "Made fna file : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/fragmented_fasta/test_R2_1.fna\n",

      "Made fna file : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/fragmented_fasta/test_R2_2.fna\n",

      "Made fna file : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/fragmented_fasta/test_R2_3.fna\n",

      "Made fna file : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/fragmented_fasta/test_R2_4.fna\n",

      "Made fna file : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/fragmented_fasta/test_R2_5.fna\n",

      "Made fna file : /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/fragmented_fasta/test_R2_6.fna\n"

     ]

    }

   ],

   "source": [

    "#Creating directory for fragmented fasta files and executing the function above. \n",

    "for F in fastq_files:\n",

    "     make_fragmented_fasta(\"%s/Data/%s/%s\"%(PATH,dir_name,F),400000,150,\"%s/Data/%s/fragmented_fasta\"%(PATH,dir_name)) "

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 50,

   "id": "contemporary-belief",

   "metadata": {},

   "outputs": [],

   "source": [

    "#Creating BLAST database.\n",

    "os.system(\"makeblastdb -in %s/const-seq.fna -dbtype nucl\"%(PATH))\n",

    "db = '%s/const-seq.fna'%(PATH)\n",

    "\n",

    "# You should be able to see the following output in your terminal \n",

    "#\n",

    "#Building a new DB, current time: 03/09/2021 13:20:38\n",

    "#New DB name:   /Users/username/GitHub/BFG-Y2H/RCP-PCR/const-seq.fna\n",

    "#New DB title:  /Users/username/GitHub/BFG-Y2H/RCP-PCR/const-seq.fna\n",

    "#Sequence type: Nucleotide\n",

    "#Keep MBits: T\n",

    "#Maximum file size: 1000000000B\n",

    "#Adding sequences from FASTA; added 32 sequences in 0.00142884 seconds."

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 51,

   "id": "visible-judgment",

   "metadata": {},

   "outputs": [],

   "source": [

    "# Deefining multi-proccessing handling.\n",

    "def subprocces_sh(core,sh_dir):\n",

    "    command_L = get_sh(sh_dir)\n",

    "    command_L = [\"sh %s/%s\"%(sh_dir,i) for i in command_L]\n",

    "    if core > len(command_L):\n",

    "        core = len(command_L)\n",

    "    n = len(command_L)/core\n",

    "    pool = mp.Pool(core)\n",

    "    feed = {}\n",

    "    for i in range(core):\n",

    "        feed.update({i:[]})\n",

    "    lp = len(command_L)\n",

    "    ky = range(0,lp)\n",

    "    v = 0\n",

    "    for i in range(lp):\n",

    "        feed[v].append(command_L[0])\n",

    "        del command_L[0]\n",

    "        v +=1\n",

    "        if (v==core):\n",

    "            v = 0\n",

    "    fed = []\n",

    "    for i in range(0,core):\n",

    "        fed.append(feed[i])\n",

    "    \n",

    "    results = pool.map(run_sh,fed)\n",

    "    pass\n",

    "\n",

    "def get_sh(x):\n",

    "    files = []\n",

    "    lis = os.listdir(\"%s\" %x)\n",

    "    for i in lis:\n",

    "        if i[-3:] == \".sh\" :\n",

    "            files.append(i)\n",

    "    return files\n",

    "\n",

    "def run_sh(sh_L):\n",

    "    for sh in sh_L:\n",

    "        print(\"Running command : %s\\n\"%(sh))\n",

    "        os.system(sh)\n",

    "    \n",

    "        \n"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 52,

   "id": "geological-liverpool",

   "metadata": {},

   "outputs": [

    {

     "name": "stdout",

     "output_type": "stream",

     "text": [

      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_1.sh\n",

      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_2.sh\n",

      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_3.sh\n",

      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_4.sh\n",

      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_5.sh\n",

      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_6.sh\n",

      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_7.sh\n",

      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_8.sh\n",

      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_9.sh\n",

      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_10.sh\n",

      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_11.sh\n",

      "Generated /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_12.sh\n"

     ]

    }

   ],

   "source": [

    "# Prepare .sh files for executing BLAST\n",

    "\n",

    "#Listing fragmented fastas files.\n",

    "fasta_files = os.listdir(\"%s/Data/%s/fragmented_fasta\" % (PATH,dir_name)) \n",

    "\n",

    "#Generating sh files.\n",

    "sh = 1\n",

    "for f in fasta_files:\n",

    "    command = \"blastn -task blastn-short -strand plus -db %s/const-seq.fna -outfmt 10 -evalue 1e-3 -query %s/Data/%s/fragmented_fasta/%s -out %s/Data/%s/blast/out.blast/%s.blast\"%(PATH,PATH,dir_name,f,PATH,dir_name,f.split(\".\")[0])\n",

    "    f_name = \"%s/Data/%s/blast/sh.blast/blast_%d.sh\"%(PATH,dir_name,sh)\n",

    "    with open(f_name,\"w\") as F:\n",

    "        F.write(command)\n",

    "        print(\"Generated %s\"%(f_name))\n",

    "    F.close()\n",

    "    sh +=1\n",

    "\n",

    "\n",

    "    "

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 53,

   "id": "normal-usage",

   "metadata": {},

   "outputs": [

    {

     "name": "stdout",

     "output_type": "stream",

     "text": [

      "Dividing and runnig jobs . . . \n",

      "Running command : sh /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_11.sh\n",

      "Running command : sh /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_4.sh\n",

      "\n",

      "\n",

      "Running command : sh /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_5.sh\n",

      "\n",

      "Running command : sh /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_1.sh\n",

      "\n",

      "Running command : sh /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_8.sh\n",

      "\n",

      "Running command : sh /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_10.sh\n",

      "\n",

      "Running command : sh /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_2.sh\n",

      "\n",

      "Running command : sh /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_9.sh\n",

      "\n",

      "Running command : sh /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_6.sh\n",

      "\n",

      "Running command : sh /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_7.sh\n",

      "\n",

      "Running command : sh /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_3.sh\n",

      "\n",

      "Running command : sh /Users/danyamamotoevans/GitHub/BFG-Y2H/RCP-PCR/Data/test/blast/sh.blast/blast_12.sh\n",

      "\n",

      "\n",

      "\n",

      "Done\n"

     ]

    }

   ],

   "source": [

    "# Executing BLAST sh files\n",

    "print(\"Dividing and runnig jobs . . . \")\n",

    "subprocces_sh(threads,\"%s/Data/%s/blast/sh.blast\"%(PATH,dir_name))\n",

    "print (\"\\n\\nDone\")"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 54,

   "id": "romance-admission",

   "metadata": {},

   "outputs": [],

   "source": [

    "#Reading reference files\n",

    "bar2num_file = \"%s/bar2num.txt\"%(PATH)\n",

    "bar_d = {}\n",

    "with open(bar2num_file,\"r\") as F:\n",

    "    for line in F:\n",

    "        cols = line.split(\",\")\n",

    "        num = cols[0]  \n",

    "        bar = cols[1]\n",

    "        bar_d[num] = bar\n",

    "    F.close()\n",

    "\n",

    "tag_f    = \"%s/%s\"%(PATH,tag_file)\n",

    "tags = []\n",

    "with open(tag_f,\"r\") as F:\n",

    "    for line in F:\n",

    "        cols = line.split(\",\")\n",

    "        #AD003,AD,BC,P01-P01\n",

    "        plate        = cols[0]\n",

    "        barcode_type = cols[1] \n",

    "        PCR_type     = cols[2] \n",

    "        tag          = cols[3] \n",

    "        tags.append([plate,barcode_type,PCR_type,tag])\n",

    "    F.close()    "

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 55,

   "id": "appropriate-helping",

   "metadata": {},

   "outputs": [],

   "source": [

    "#Function to parse fasta file to doctionary.\n",

    "def fasta2dict(name):\n",

    "    d = {}\n",

    "    for record in SeqIO.parse(name,\"fasta\"):\n",

    "        d.update({record.id :  str(record.seq)})\n",

    "    return d\n",

    "\n",

    "\n",

    "#Function to parse BLAST output to dictionary\n",

    "def parse_blast_output2dict(blast_R1,blast_R2,PATH,dir_name,tag_f): \n",

    "    # BLAST database sequences in dict format\n",

    "    seq_DB   = fasta2dict(\"%s/const-seq.fna\"%(PATH))\n",

    "    \n",

    "    \n",

    "    blast_d = {}\n",

    "    \n",

    "    with open(blast_R1) as F:\n",

    "        for line in F:\n",

    "            cols           = line.split(\"\\n\")[0].split(\",\")\n",

    "            #print(cols)\n",

    "            read           = cols[0]   \n",

    "            subject        = cols[1]  \n",

    "            str_on_read    = int(cols[6])  \n",

    "            end_on_read    = int(cols[7])\n",

    "            str_on_subject = int(cols[8])\n",

    "            end_on_subject = int(cols[9])\n",

    "            evalue         = float(cols[10])\n",

    "            \n",

    "           \n",

    "            if (str_on_read < end_on_read):\n",

    "                if (str_on_subject ==1):\n",

    "                    if (end_on_subject==len(seq_DB[subject])):\n",

    "                        element = {\"str\":str_on_read,\n",

    "                                   \"end\":end_on_read,\n",

    "                                   \"evalue\":evalue}\n",

    "                        try:\n",

    "                            blast_d[read][\"R1\"][subject] = element\n",

    "                        except KeyError:\n",

    "                            try:\n",

    "                                blast_d[read][\"R1\"]       = {}\n",

    "                                blast_d[read][\"R1\"][subject] = element\n",

    "                            except KeyError:\n",

    "                                blast_d[read] = {}\n",

    "                                blast_d[read][\"R1\"]       = {}\n",

    "                                blast_d[read][\"R1\"][subject] = element\n",

    " \n",

    "        F.close()\n",

    "    #pprint(blast_d)  \n",

    "    with open(blast_R2) as F:\n",

    "        for line in F:\n",

    "            cols             = line.split(\",\")\n",

    "            read             = cols[0]   \n",

    "            subject          = cols[1]   \n",

    "            str_on_read      = int(cols[6]   )\n",

    "            end_on_read      = int(cols[7]   )\n",

    "            str_on_subject   = int(cols[8]   )\n",

    "            end_on_subject   = int(cols[9]   )\n",

    "            evalue           = float(cols[10])  \n",

    "    \n",

    "            if ((str_on_read < end_on_read) and (str_on_subject ==1) and (end_on_subject==len(seq_DB[subject]))):\n",

    "                element = {\"str\":str_on_read,\n",

    "                               \"end\":end_on_read,\n",

    "                               \"evalue\":evalue}\n",

    "                try:\n",

    "                    blast_d[read][\"R2\"][subject] = element\n",

    "                except KeyError:\n",

    "                    try:\n",

    "                        blast_d[read][\"R2\"] = {}\n",

    "                        blast_d[read][\"R2\"][subject] = element\n",

    "                    except KeyError:\n",

    "                        blast_d[read] = {}\n",

    "                        blast_d[read][\"R2\"] = {}\n",

    "                        blast_d[read][\"R2\"][subject] = element\n",

    "                \n",

    "        F.close()\n",

    "        \n",

    "    \n",

    "    return blast_d         "

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 56,

   "id": "featured-chinese",

   "metadata": {},

   "outputs": [],

   "source": [

    "# Function to assign RCP-PCR category and extract index sequences. \n",

    "def assign_category(read_d,read_R1_seq,read_R2_seq):\n",

    "\n",

    "    R1 = read_d['R1']\n",

    "    R2 = read_d['R2']\n",

    "\n",

    "    # PS1.0 and PS2.0 at the reasonable positions? (end at <40bp)\n",

    "    PS_pos = 0\n",

    "\n",

    "    P_SEQ1 = 0\n",

    "    P_SEQ2 = 0\n",

    "\n",

    "    if( ('PS1.0-primer'in R1.keys()) and ('PS2.0-primer' in R2.keys()) ):\n",

    "        if( (R1['PS1.0-primer']['end_on_read'] < 40) and (R2['PS2.0-primer']['end_on_read'] < 40) ):\n",

    "            P_SEQ1 = read_R1_seq[R1['PS1.0-primer']['str_on_read']-10:-2]\n",

    "            P_SEQ2 = read_R2_seq[R2['PS2.0-primer']['str_on_read']-10:-2]\n",

    "            PS_pos = 1\n",

    "            \n",

    "    # Row and Column priming sites from the reasonable positions? (start at <50bp)\n",

    "    # Which category? DB-BC / DB-lox / AD-BC / AD-lox?\n",

    "    DB_BC = 0\n",

    "    DB_lox = 0\n",

    "    AD_BC = 0\n",

    "    AD_lox = 0\n",

    "    \n",

    "    \n",

    "\n",

    "    if(PS_pos ==1):\n",

    "        R_seq = {}\n",

    "        C_seq = {}\n",

    "        #DB-BC\n",

    "        if( ('DBU1-primer' in R1.keys()) and ('DBD2-primer' in R2.keys())):\n",

    "            if (R1['PS1.0-primer']['end_on_read'] < R1['DBU1-primer']['str_on_read']):\n",

    "               if (R1['DBU1-primer']['str_on_read'] < 50):\n",

    "                   if (R2['PS2.0-primer']['end_on_read'] < R2['DBD2-primer']['str_on_read']):\n",

    "                        if (R2['DBD2-primer']['str_on_read'] < 50):\n",

    "\n",

    "                            R_seq['DB-BC'] = read_R1_seq[R1['PS1.0-primer']['end_on_read']+1:R1['DBU1-primer']['str_on_read']+1-2]\n",

    "                            C_seq['DB-BC'] = read_R2_seq[R2['PS2.0-primer']['end_on_read']+1:R2['DBD2-primer']['str_on_read']+1-2] \n",

    "                            DB_BC = 1\n",

    "\n",

    "               \n",

    "        #DB-lox\n",

    "        if (('DBloxP-primer' in R1.keys()) and ('DBlox2272-primer' in R2.keys())):     \n",

    "            if(R1['PS1.0-primer']['end_on_read'] < R1['DBloxP-primer']['str_on_read']):\n",

    "               if( R1['DBloxP-primer']['str_on_read'] < 50 ):\n",

    "                   if (R2['PS2.0-primer']['end_on_str']< R2['DBlox2272-primer']['str_on_read']):\n",

    "                       if(R2['DBlox2272-primer']['str_on_read'] < 50):\n",

    "               \n",

    "                            R_seq['DB-lox'] = read_R1_seq[R1['PS1.0-primer']['end_on_read']+1:R1['DBloxP-primer']['str_on_read']+1-2]\n",

    "                            C_seq['DB-lox'] = read_R2_seq[R2['PS2.0-primer']['end_on_read']+1:R2['DBlox2272-primer']['str_on_read']+1-2] \n",

    "                            DB_lox = 1\n",

    "        #AD-BC\n",

    "        if( ('ADU1-primer' in R1.keys()) and ('ADD2-primer' in R2.keys()) ):\n",

    "            if( (R1['PS1.0-primer']['end_on_read'] < R1['ADU1-primer']['str_on_read'])):\n",

    "               if (R1['ADU1-primer']['str_on_read'] < 50):\n",

    "                   if (R2['PS2.0-primer']['end_on_read'] < R2['ADD2-primer']['str_on_read']):\n",

    "                        if (R2['ADD2-primer']['str_on_read'] < 50):\n",

    "\n",

    "                            R_seq['AD-BC'] = read_R1_seq[R1['PS1.0-primer']['end_on_read']+1:R1['ADU1-primer']['str_on_read']+1-2]\n",

    "                            C_seq['AD-BC'] = read_R2_seq[R2['PS2.0-primer']['end_on_read']+1:R2['ADD2-primer']['str_on_read']+1-2] \n",

    "                            AD_BC = 1\n",

    "\n",

    "               \n",

    "        #AD-lox\n",

    "        if ('ADloxP-primer' in R1.keys()) and ('ADlox2272-primer' in R2.keys())  :   \n",

    "            if(R1['PS1.0-primer']['end_on_read'] < R1['ADloxP-primer']['str_on_read']):\n",

    "               if ( R1['ADloxP-primer']['str_on_read'] < 50 ):\n",

    "                   if (R2['PS2.0-primer']['end_on_str']< R2['ADlox2272-primer']['str_on_read']):\n",

    "                       if (R2['ADlox2272-primer']['str_on_read'] < 50):\n",

    "               \n",

    "                            R_seq['AD-lox'] = read_R1_seq[R1['PS1.0-primer']['end_on_read']+1:R1['ADloxP-primer']['str_on_read']+1-2]\n",

    "                            C_seq['AD-lox'] = read_R2_seq[R2['PS2.0-primer']['end_on_read']+1:R2['ADlox2272-primer']['str_on_read']+1-2] \n",

    "                            AD_lox = 1\n",

    "\n",

    "\n",

    "        # Specific category assignment?\n",

    "        category = 0\n",

    "        R_seq = 0\n",

    "        C_seq = 0\n",

    "\n",

    "        if(DB_BC + DB_lox + AD_BC + AD_lox == 1):\n",

    "            if(DB_BC==1):\n",

    "                category = 'DB-BC'\n",

    "            elif(DB_lox==1):\n",

    "                category = 'DB-lox'\n",

    "            elif(AD_BC==1):\n",

    "                category = 'AD-BC'\n",

    "            elif(AD_lox==1):\n",

    "                category = 'AD-lox'\n",

    "\n",

    "\n",

    "        R_SEQ = R_seq[category]\n",

    "        C_SEQ = C_seq[category]\n",

    "\n",

    "               \n",

    "    return (category,P_SEQ1,P_SEQ2,R_SEQ,C_SEQ)\n",

    "\n"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 57,

   "id": "promotional-fellow",

   "metadata": {},

   "outputs": [],

   "source": [

    "# Defining small functions for calling barcode category and tags index.\n",

    "\n",

    "def rv_comp(seq):\n",

    "    bases = {\"A\":\"T\",\"T\":\"A\",\"G\":\"C\",\"C\":\"G\",\"N\":\"N\"}\n",

    "    seq_l = list(seq)\n",

    "    rv_comp = [bases[base] for base in seq_l]\n",

    "    rv_comp.reverse()\n",

    "    rv_comp\n",

    "    return (\"\").join(rv_comp)\n",

    "\n",

    "\n",

    "def BC_match(R1,R2):\n",

    "    r1 = R1\n",

    "    r2 = rv_comp(R2)        \n",

    "\n",

    "    rel = {}\n",

    "    for i in range(0,length(r1)):\n",

    "        n1 = r1[i]\n",

    "        for j in range(0,length(r2)):\n",

    "            n2 = r2[j]\n",

    "            if(n1 == n2):\n",

    "                diff = i-j\n",

    "                try:\n",

    "                    rel[diff] +=1\n",

    "                except KeyError:\n",

    "                    rel[diff] = 1\n",

    "\n",

    "    max_match_diff = max(rel.iteritems(), key=operator.itemgetter(1))[0]                 \n",

    "                    \n",

    "    if rel[max_match_diff] >= 18:\n",

    "        diff  = max_match_diff\n",

    "        count = rel[max_match_diff]\n",

    "        \n",

    "        r1_bc = r1\n",

    "        r2_bc = r2[diff:]\n",

    "           \n",

    "        for i in range(0,len(r1)):\n",

    "    \n",

    "        \n",

    "            nuc_r1 = r1_bc[i]\n",

    "            if (len(r2_bc)+1) > i:\n",

    "                nuc_r2 = r2_bc[i]\n",

    "                if nuc_r1 == nuc_r2:\n",

    "                    n = nuc_r1\n",

    "                elif((nuc_r1==\"N\") and (nuc_r2 != \"N\")):\n",

    "                    n = nuc_r2\n",

    "                elif((nuc_r1!=\"N\") and (nuc_r2 == \"N\")):\n",

    "                    n = nuc_r2\n",

    "                else:\n",

    "                    n = \"N\"\n",

    "            else:\n",

    "                n = nuc_r1\n",

    "            \n",

    "            tag.append(n)\n",

    "\n",

    "    return (\"\").join(tag)\n",

    "\n",

    "def tag_calling(bar2num,seq):\n",

    "    count = {}\n",

    "    tag_hits = []\n",

    "    for tag in bar2num:\n",

    "    \n",

    "        for k in range(0,len(tag)):\n",

    "            k_nuc = tag[k]\n",

    "            \n",

    "            for i in tange(0,length(seq)):\n",

    "                i_nuc = seq[i]\n",

    "\n",

    "                rel = k-i\n",

    "                if(k_nuc == i_nuc):\n",

    "                    try:\n",

    "                        count[rel] += 1\n",

    "                    except KeyError:\n",

    "                        count[rel] = 1\n",

    "                else:\n",

    "                    try:\n",

    "                        count[rel] += 0\n",

    "                    except KeyError:\n",

    "                        count[rel] = 0\n",

    "                \n",

    "                \n",

    "\n",

    "        max_match_rel = max(count.iteritems(), key=operator.itemgetter(1))[0]\n",

    "        tag_hits.append(tag,max_match_rel,count[max_match_rel])\n",

    "   \n",

    "\n",

    "    target_hits.sort(key=lambda x: x[2])\n",

    "    \n",

    "\n",

    "    if(target_hits[0][2] == target_hits[1][2]):\n",

    "        val = 0\n",

    "    elif(target_hits[0][2]>5): \n",

    "        called_bar = bar2num[target_hits[0][0]]\n",

    "        val = called_bar\n",

    "    else:\n",

    "        val = 0\n",

    "\n",

    "    return val"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": 58,

   "id": "accessory-field",

   "metadata": {},

   "outputs": [],

   "source": [

    "# Definfing function for analysing status of each element within barcode cassette.\n",

    "def analyze_stat(category,R1,R2,seq_DB):\n",

    "    stat = {\"R1\":{},\"R2\":{}}\n",

    "    \n",

    "    if category == \"DB-BC\":\n",

    "        \n",

    "        # Setting default status \n",

    "        stat[\"R1\"]['DBU1-primer']  = 'there'\n",

    "        stat[\"R1\"]['cDBU2-primer'] = 'absent'\n",

    "        stat[\"R1\"]['UPTAG-frag']        = 'absent'\n",

    "        stat[\"R1\"]['lox2272']      = 'absent'\n",

    "\n",

    "        stat[\"R2\"]['DBD2-primer']  = 'there'\n",

    "        stat[\"R2\"]['cDBD1-primer'] = 'absent'\n",

    "        stat[\"R2\"]['cDNTAG-frag']       = 'absent'\n",

    "\n",

    "\n",

    "        ##### Existence check; UPTAG\n",

    "        if( 'cDBU2-primer' in R1.keys()):\n",

    "            if( R1['DBU1-primer']['end_on_read'] < R1['cDBU2-primer']['str_on_read']):\n",

    "                TAG_str = R1['DBU1-primer']['end_on_read']+1 -1\n",

    "                TAG_end = R1['cDBU2-primer']['str_on_read']-1 -1\n",

    "\n",

    "                stat[\"R1\"]['cDBU2-primer'] = 'there'\n",

    "                stat[\"R1\"]['UPTAG-frag']        =  R1[\"seq\"][TAG_str:TAG_end]\n",

    "\n",

    "\n",

    "\n",

    "        ##### Existence check; lox2272\n",

    "        if('cDBU2-primer'in R1.keys()):\n",

    "            if('lox2272' in R1.keys()):\n",

    "                if(R1['cDBU2-primer']['end_on_read'] < R1['lox2272']['str_on_read']):\n",

    "                    offset = R1['lox2272']['str_on_read'] - R1['cDBU2-primer']['end_on_read'] -1\n",

    "                    stat[\"R1\"]['lox2272'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "        ##### Existence check; DNTAG\n",

    "        if('cDBD1-primer' in R2.keys()):\n",

    "            if(R2['DBD2-primer']['end_on_read'] < R2['cDBD1-primer']['str_on_read']):\n",

    "                TAG_str = R2['DBD2-primer']['emnd_on_read'] +1 -1\n",

    "                TAG_end = R2['cDBD1-primer']['str_on_read']-1 -1\n",

    "\n",

    "                stat[\"R2\"]['cDBD1-primer'] = 'there'\n",

    "                stat[\"R2\"]['cDNTAG-frag']       = R2[\"seq\"][TAG_str:TAG_end]   \n",

    "\n",

    "\n",

    "        ##### Sequence match check\n",

    "        for read in stat:\n",

    "            for primer in stat[read]:\n",

    "                s =  stat[read][primer].split(\";\")\n",

    "                if s[0] == 'there':\n",

    "                    read_seq = R1['seq'][R1[primer][\"str_on_read\"]:R1[primer][\"end_on_read\"]] \n",

    "                    if read_seq == seq_DB[primer]:\n",

    "                        stat[read][primer].replace(\"there\",\"match\")\n",

    "                    else:\n",

    "                        stat[read][primer].replace(\"there\",\"no-match\")\n",

    "    \n",

    "    if category ==\"DB-lox\":\n",

    "        # Setting default status \n",

    "        stat[\"R1\"]['DBloxP-primer']   = 'there'\n",

    "        stat[\"R1\"]['cloxP']           = 'absent'\n",

    "        stat[\"R1\"]['DBU1-primer']     = 'absent'\n",

    "        stat[\"R1\"]['UPTAG-frag']      = 'absent'                        \n",

    "        stat[\"R1\"]['cDBU2-primer']    = 'absent'\n",

    "\n",

    "        stat[\"R2\"]['DBlox2272-primer']= 'there'\n",

    "        stat[\"R2\"]['clox2272']        = 'absent'\n",

    "        stat[\"R2\"]['DBU2-primer']= 'there'\n",

    "        stat[\"R2\"]['cUPTAG-frag']= 'there'\n",

    "        stat[\"R2\"]['cDBU1-primer']= 'there'\n",

    "        \n",

    "        ##### Existence check; cLoxP\n",

    "        if( 'cloxP' in R1.keys()):\n",

    "            if( R1['DBloxP-primer']['end_on_read'] < R1['cloxP']['str_on_read']):\n",

    "                offset = R1['cloxP']['str_on_read'] - R1['DBloxP-primer']['end_on_read'] -1\n",

    "                stat[\"R1\"]['cloxP'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "        #### Existence check; DBU1-primer\n",

    "        if( 'cloxP' in R1.keys()):\n",

    "            if( 'DBU1-primer' in R1.keys()):    \n",

    "                if( R1['cloxP']['end_on_read'] < R1['DBU1-primer']['str_on_read']):\n",

    "                    offset = R1['DBU1-primer']['str_on_read'] - R1['cloxP']['end_on_read'] -1\n",

    "                    stat[\"R1\"]['DBU1-primer'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "        #### Existence check; cDBU2-primer\n",

    "        if( 'cDBU2-primer' in R1.keys()):\n",

    "            if( 'DBU1-primer' in R1.keys()):    \n",

    "                if( R1['DBU1-primer']['end_on_read'] < R1['cDBU2-primer']['str_on_read']):\n",

    "                    offset = R1['cDBU2-primer']['str_on_read'] - R1['DBU1-primer']['end_on_read'] -1\n",

    "                    stat[\"R1\"]['cDBU2-primer'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "                    TAG_str = R1['DBU1-primer']['end_on_read']+1\n",

    "                    TAG_end = R1['cDBU2-primer']['str_on_read']-1-1\n",

    "                    stat[\"R1\"]['UPTAG_frag'] = R1[\"seq\"][TAG_str:TAG_end]\n",

    "\n",

    "        ##### Existence check; clox2272\n",

    "        if( 'clox2272' in R1.keys()):\n",

    "            if( R1['cDBlox2272-primer']['end_on_read'] < R1['clox2272']['str_on_read']):\n",

    "                offset = R1['clox2272']['str_on_read'] - R1['DBlox2272-primer']['end_on_read'] -1\n",

    "                stat[\"R1\"]['clox2272'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "        #### Existence check; DBU2-primer\n",

    "        if( 'clox2272' in R2.keys()):\n",

    "            if( 'DBU2-primer' in R2.keys()):    \n",

    "                if( R2['clox2272']['end_on_read'] < R2['DBU2-primer']['str_on_read']):\n",

    "                    offset = R2['DBU2-primer']['str_on_read'] - R2['clox2272']['end_on_read'] -1\n",

    "                    stat[\"R2\"]['DBU2-primer'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "        #### Existence check; cDBU1-primer\n",

    "        if( 'DBU2-primer' in R2.keys()):\n",

    "            if( 'cDBU1-primer' in R2.keys()):    \n",

    "                if( R2['DBU2-primer']['end_on_read'] < R2['cDBU1-primer']['str_on_read']):\n",

    "                    offset = R2['cDBU1-primer']['str_on_read'] - R2['DBU2-primer']['end_on_read'] -1\n",

    "                    stat[\"R2\"]['cDBU1-primer'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "                    TAG_str = R2['DBU2-primer']['end_on_read']+1\n",

    "                    TAG_end = R2['cDBU1-primer']['str_on_read']-1-1\n",

    "                    stat[\"R2\"]['UPTAG_frag'] = R2[\"seq\"][TAG_str:TAG_end]                       \n",

    "                                \n",

    "\n",

    "        ##### Sequence match check\n",

    "        for read in stat:\n",

    "            for primer in stat[read]:\n",

    "                s =  stat[read][primer].split(\";\")\n",

    "                if s[0] == 'there':\n",

    "                    read_seq = R1['seq'][R1[primer][\"str_on_read\"]:R1[primer][\"end_on_read\"]] \n",

    "                    if read_seq == seq_DB[primer]:\n",

    "                        stat[read][primer].replace(\"there\",\"match\")\n",

    "                    else:\n",

    "                        stat[read][primer].replace(\"there\",\"no-match\")                      \n",

    "        \n",

    "        #### Fragment match \n",

    "        if stat[\"R1\"][\"UPTAG-frag\"] != \"absent\":\n",

    "            if stat[\"R2\"][\"cUPTAG-frag\"] != \"absent\":\n",

    "                frag  = stat[\"R1\"][\"UPTAG-frag\"]\n",

    "                cfrag = stat[\"R2\"][\"cUPTAG-frag\"]\n",

    "                                \n",

    "                BC    = BC_match(frag,cfrag)\n",

    "                                \n",

    "                stat['merged-UPTAG'] = BC          \n",

    "    \n",

    "    \n",

    "                                \n",

    "    if category == \"AD-BC\":\n",

    "        \n",

    "        # Setting default status \n",

    "        stat[\"R1\"]['ADU1-primer']  = 'there'\n",

    "        stat[\"R1\"]['cADU2-primer'] = 'absent'\n",

    "        stat[\"R1\"]['UPTAG-frag']   = 'absent'\n",

    "        \n",

    "        stat[\"R2\"]['ADD2-primer']  = 'there'\n",

    "        stat[\"R2\"]['cADD1-primer'] = 'absent'\n",

    "        stat[\"R2\"]['cDNTAG-frag']  = 'absent'\n",

    "        stat[\"R2\"]['loxP']         = 'absent'\n",

    "                                \n",

    "\n",

    "\n",

    "        ##### Existence check; UPTAG\n",

    "        if( 'cADU2-primer' in R1.keys()):\n",

    "            if( R1['ADU1-primer']['end_on_read'] < R1['cADU2-primer']['str_on_read']):\n",

    "                TAG_str = R1['ADU1-primer']['end_on_read']+1 -1\n",

    "                TAG_end = R1['cADU2-primer']['str_on_read']-1 -1\n",

    "\n",

    "                stat[\"R1\"]['cADU2-primer'] = 'there'\n",

    "                stat[\"R1\"]['UPTAG-frag']        =  R1[\"seq\"][TAG_str:TAG_end]\n",

    "\n",

    "\n",

    "\n",

    "        ##### Existence check; loxP\n",

    "        if('cADD1-primer'in R1.keys()):\n",

    "            if('loxP' in  R1.keys()):\n",

    "                if(R1['cADD1-primer']['end_on_read'] < R1['loxP']['str_on_read']):\n",

    "                    offset = R1['loxP']['str_on_read'] - R1['ADD1-primer']['end_on_read'] -1\n",

    "                    stat[\"R1\"]['loxP'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "        ##### Existence check; DNTAG\n",

    "        if('cADD1-primer' in R2.keys()):\n",

    "            if(R2['ADD2-primer']['end_on_read'] < R2['cADD1-primer']['str_on_read']):\n",

    "                TAG_str = R2['ADD2-primer']['end_on_read'] +1 -1\n",

    "                TAG_end = R2['cADD1-primer']['str_on_read']-1 -1\n",

    "\n",

    "                stat[\"R2\"]['cADD1-primer'] = 'there'\n",

    "                stat[\"R2\"]['cDNTAG-frag']  = R2[\"seq\"][TAG_str:TAG_end]   \n",

    "\n",

    "\n",

    "        ##### Sequence match check\n",

    "        for read in stat:\n",

    "            for primer in stat[read]:\n",

    "                s =  stat[read][primer].split(\";\")\n",

    "                if s[0] == 'there':\n",

    "                    read_seq = R1['seq'][R1[primer][\"str_on_read\"]:R1[primer][\"end_on_read\"]] \n",

    "                    if read_seq == seq_DB[primer]:\n",

    "                        stat[read][primer].replace(\"there\",\"match\")\n",

    "                    else:\n",

    "                        stat[read][primer].replace(\"there\",\"no-match\")\n",

    "    \n",

    "    if category ==\"AD-lox\":\n",

    "        # Setting default status \n",

    "        stat[\"R1\"]['ADloxP-primer']   = 'there'\n",

    "        stat[\"R1\"]['cloxP']           = 'absent'\n",

    "        stat[\"R1\"]['ADD1-primer']     = 'absent'\n",

    "        stat[\"R1\"]['DNTAG-frag']      = 'absent'                        \n",

    "        stat[\"R1\"]['cADD2-primer']    = 'absent'\n",

    "\n",

    "        stat[\"R2\"]['ADlox2272-primer']= 'there'\n",

    "        stat[\"R2\"]['clox2272']        = 'absent'\n",

    "        stat[\"R2\"]['ADD2-primer']= 'there'\n",

    "        stat[\"R2\"]['cDNTAG-frag']= 'there'\n",

    "        stat[\"R2\"]['cADD1-primer']= 'there'\n",

    "        \n",

    "        ##### Existence check; cLoxP\n",

    "        if( 'cloxP' in R1.keys()):\n",

    "            if( R1['ADloxP-primer']['end_on_read'] < R1['cloxP']['str_on_read']):\n",

    "                offset = R1['cloxP']['str_on_read'] - R1['ADloxP-primer']['end_on_read'] -1\n",

    "                stat[\"R1\"]['cloxP'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "        #### Existence check; ADD1-primer\n",

    "        if( 'cloxP' in R1.keys()):\n",

    "            if( 'ADD1-primer' in R1.keys()):    \n",

    "                if( R1['cloxP']['end_on_read'] < R1['ADD1-primer']['str_on_read']):\n",

    "                    offset = R1['ADD1-primer']['str_on_read'] - R1['cloxP']['end_on_read'] -1\n",

    "                    stat[\"R1\"]['ADD1-primer'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "        #### Existence check; cADD2-primer\n",

    "        if( 'cADD2-primer' in R1.keys()):\n",

    "            if( 'ADD1-primer' in R1.keys()):    \n",

    "                if( R1['ADD1-primer']['end_on_read'] < R1['cADD2-primer']['str_on_read']):\n",

    "                    offset = R1['cADD2-primer']['str_on_read'] - R1['ADD1-primer']['end_on_read'] -1\n",

    "                    stat[\"R1\"]['cADD2-primer'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "                    TAG_str = R1['ADD1-primer']['end_on_read']+1\n",

    "                    TAG_end = R1['cADD2-primer']['str_on_read']-1-1\n",

    "                    stat[\"R1\"]['UPTAG_frag'] = R1[\"seq\"][TAG_str:TAG_end]\n",

    "\n",

    "        ##### Existence check; clox2272\n",

    "        if( 'clox2272' in R1.keys()):\n",

    "            if( R1['ADlox2272-primer']['end_on_read'] < R1['clox2272']['str_on_read']):\n",

    "                offset = R1['clox2272']['str_on_read'] - R1['ADlox2272-primer']['end_on_read'] -1\n",

    "                stat[\"R1\"]['clox2272'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "        #### Existence check; ADD2-primer\n",

    "        if( 'clox2272' in R2.keys()):\n",

    "            if( 'ADD2-primer' in R2.keys()):    \n",

    "                if( R2['clox2272']['end_on_read'] < R2['ADD2-primer']['str_on_read']):\n",

    "                    offset = R2['ADD2-primer']['str_on_read'] - R2['clox2272']['end_on_read'] -1\n",

    "                    stat[\"R2\"]['ADD2-primer'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "        #### Existence check; cADD1-primer\n",

    "        if( 'ADD2-primer' in R2.keys()):\n",

    "            if( 'cADD1-primer' in R2.keys()):    \n",

    "                if( R2['ADD2-primer']['end_on_read'] < R2['cADD1-primer']['str_on_read']):\n",

    "                    offset = R2['cADD1-primer']['str_on_read'] - R2['ADD2-primer']['end_on_read'] -1\n",

    "                    stat[\"R2\"]['cADD1-primer'] = 'there;offset=%d'%(offset)\n",

    "\n",

    "                    TAG_str = R2['ADD2-primer']['end_on_read']+1\n",

    "                    TAG_end = R2['cADD1-primer']['str_on_read']-1-1\n",

    "                    stat[\"R2\"]['UPTAG_frag'] = R2[\"seq\"][TAG_str:TAG_end]                       \n",

    "                                \n",

    "\n",

    "        ##### Sequence match check\n",

    "        for read in stat:\n",

    "            for primer in stat[read]:\n",

    "                s =  stat[read][primer].split(\";\")\n",

    "                if s[0] == 'there':\n",

    "                    read_seq = R1['seq'][R1[primer][\"str_on_read\"]:R1[primer][\"end_on_read\"]] \n",

    "                    if read_seq == seq_DB[primer]:\n",

    "                        stat[read][primer].replace(\"there\",\"match\")\n",

    "                    else:\n",

    "                        stat[read][primer].replace(\"there\",\"no-match\")                      \n",

    "        \n",

    "        #### Fragment match \n",

    "        if stat[\"R1\"][\"UPTAG-frag\"] != \"absent\":\n",

    "            if stat[\"R2\"][\"cUPTAG-frag\"] != \"absent\":\n",

    "                frag  = stat[\"R1\"][\"UPTAG-frag\"]\n",

    "                cfrag = stat[\"R2\"][\"cUPTAG-frag\"]\n",

    "                                \n",

    "                BC    = BC_match(frag,cfrag)\n",

    "                                \n",

    "                stat['merged-UPTAG'] = BC          \n",

    "        \n",

    "    return stat"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "id": "compatible-thirty",

   "metadata": {},
   "outputs": [],

   "source": [

    "data = {}\n",

    "\n",

    "f_pairs = []\n",

    "for f in range(0, len(fasta_files)):\n",

    "    for f2 in range(0, len(fasta_files)):\n",

    "        if \"R1\" in fasta_files[f]:\n",

    "            if fasta_files[f].replace(\"R1\",\"R2\") == fasta_files[f2]:\n",

    "                f_pairs.append([fasta_files[f].split(\".\")[0].split(\"_\")[-1],fasta_files[f],fasta_files[f2]])\n",

    "f_pairs.sort(key=lambda x: x[0])\n",

    "#pprint(f_pairs)\n",

    "\n",

    "for small_file in f_pairs:\n",

    "    R1_ID = small_file[1].split(\".\")[0]\n",

    "    R2_ID = small_file[2].split(\".\")[0]\n",

    "\n",

    "    R1_fna = '%s/Data/%s/fragmented_fasta/%s'%(PATH,dir_name,small_file[1])\n",

    "    R2_fna = '%s/Data/%s/fragmented_fasta/%s'%(PATH,dir_name,small_file[2])\n",

    "\n",

    "    R1_blast = '%s/Data/%s/blast/out.blast/%s.blast'%(PATH,dir_name,R1_ID)\n",

    "    R2_blast = '%s/Data/%s/blast/out.blast/%s.blast'%(PATH,dir_name,R2_ID)\n",

    "\n",

    "    d = parse_blast_output2dict(R1_blast,R2_blast,PATH,dir_name,tag_f)\n",

    "    pprint(d)\n",

    "    #print(Stop)"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "id": "attractive-occurrence",

   "metadata": {},

   "outputs": [],

   "source": [

    "\n",

    "my $data2;\n",

    "while(my($read,$value) = each %$data){\n",

    "    my $R1     = $value->{R1};\n",

    "    my $R2     = $value->{R2};\n",

    "    my $seq;\n",

    "    $seq->{R1} = $seq_reads->{R1}->{$read}->{seq};\n",

    "    $seq->{R2} = $seq_reads->{R2}->{$read}->{seq};\n",

    "\n",

    "\n",

    "\n",

    "    # PS1.0 and PS2.0 at the reasonable positions? (end at <40bp)\n",

    "    # Row and Column priming sites from the reasonable positions? (start at <50bp)\n",

    "    # Which category? DB-BC / DB-lox / AD-BC / AD-lox?\n",

    "    # Specific category assignment?\n",

    "    # Row, Column and Plate tags?\n",

    "\n",

    "    my ($category,$P1_seq,$P2_seq,$R_seq,$C_seq) = &assign_category($value,$R1,$R2,$seq);\n",

    "    #print Dumper ($category,$P1_seq,$P2_seq,$R_seq,$C_seq);\n",

    "\n",

    "\n",

    "    my $P1_num = ($P1_seq && length($P1_seq) < 12)? &barcode_matching($bar2num,$P1_seq):0;\n",

    "    my $P2_num = ($P2_seq && length($P2_seq) < 12)? &barcode_matching($bar2num,$P2_seq):0;\n",

    "    my $R_num  = ($R_seq  && length($R_seq)  < 12)? &barcode_matching($bar2num,$R_seq) :0;\n",

    "    my $C_num  = ($C_seq  && length($C_seq)  < 12)? &barcode_matching($bar2num,$C_seq) :0;\n",

    "\n",

    "    #############################\n",

    "    # Process for each category #\n",

    "    #############################\n",

    "\n",

    "    if($category && $P1_num*$P2_num*$R_num*$C_num){\n",

    "\n",

    "\t$P1_num = sprintf \"%.1f\", $P1_num/10;\n",

    "\t$P1_num =~ s/\\.//g;\n",

    "\t$P2_num = sprintf \"%.1f\", $P2_num/10;\n",

    "\t$P2_num =~ s/\\.//g;\n",

    "\t$R_num  = sprintf \"%.1f\", $R_num/10;\n",

    "\t$R_num  =~ s/\\.//g;\n",

    "\t$C_num  = sprintf \"%.1f\", $C_num/10;\n",

    "\t$C_num  =~ s/\\.//g;\n",

    "\n",

    "    my ($P_TAG,$R_TAG,$C_TAG) = (\"P$P1_num\\-P$P2_num\",\"R$R_num\",\"C$C_num\");\n",

    "\t#print \"$category\\t$P_TAG\\t$R_TAG\\t$C_TAG\\n\";\n",

    "\n",

    "\n",

    "\tmy $stat;\n",

    "\n",

    "`\n",

    "\tmy ($type1,$type2) = split /\\-/, $category;\n",

    "\tif($tag_strct->{$type1}->{$type2}->{$P_TAG}){\n",

    "\t    my $plate_name = $tag_strct->{$type1}->{$type2}->{$P_TAG};\n",

    "\t    $data2->{$category}->{$plate_name}->{$R_TAG}->{$C_TAG}->{$read} = $stat;\n",

    "\t}\n",

    "    }\n",

    "}\n",

    "\n",

    "print Dumper $data2;"

   ]

  },

  {

   "cell_type": "code",

   "execution_count": null,

   "id": "above-syndication",

   "metadata": {},

   "outputs": [],

   "source": []

  }

 ],

 "metadata": {

  "kernelspec": {

   "display_name": "Python 3",

   "language": "python",

   "name": "python3"

  },

  "language_info": {

   "codemirror_mode": {

    "name": "ipython",

    "version": 3

   },

   "file_extension": ".py",

   "mimetype": "text/x-python",

   "name": "python",

   "nbconvert_exporter": "python",

   "pygments_lexer": "ipython3",

   "version": "3.6.1"

  }

 },

 "nbformat": 4,

 "nbformat_minor": 5

}

