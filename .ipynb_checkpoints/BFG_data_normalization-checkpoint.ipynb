{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "raising-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import ast\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from func import normalization as norm\n",
    "\n",
    "##############################################\n",
    "# JUPYTER-NOTEBOOK FOR NORMALIZING BARCODE   #\n",
    "# COUNTS FROM BFG-PCA SCREENINGS             #\n",
    "# Last modified by Daniel Evans-Yamamoto     #\n",
    "##############################################\n",
    "\n",
    "PATH = os.path.abspath(\".\")\n",
    "run_name = \"test\"\n",
    "norm_dir = '%s/Data/%s/normalization'%(PATH,run_name)\n",
    "if not os.path.isdir(norm_dir):\n",
    "    os.makedirs(norm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "previous-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Definfing the file location\n",
    "count_f        = \"%s/Data/%s/barcode_counts/counts.txt\"%(PATH,run_name)\n",
    "\n",
    "#  Reading dict object from the text files with count data\n",
    "count     = norm.reading(count_f)\n",
    "# Reading tag information and barcode database \n",
    "multiplex_tag  = norm.get_tagdata('%s/%s/%s_tag.csv'%(PATH,run_name,run_name))#Change this to your own file. Read wiki for instructions.\n",
    "db             = norm.get_mapdata('%s/%s/%s_database.csv'%(PATH,run_name,run_name))#Change this to your own file. Read wiki for instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "complimentary-franklin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Sample Total reads\n",
      "P01-P01 DMSO_72 1962\n",
      "P02-P02 DMSO_96 1589\n",
      "P03-P03 MTX1_72 2370\n",
      "P04-P04 MTX1_96 1484\n",
      "P05-P05 MTX10_72 4536\n",
      "P06-P06 MTX10_96 3816\n",
      "P07-P07 MTX100_72 6278\n",
      "P08-P08 MTX100_96 5392\n",
      "P09-P09 MTX200_72 5295\n",
      "P10-P10 MTX200_96 5420\n"
     ]
    }
   ],
   "source": [
    "# Examine total reads;\n",
    "norm.tot_reads(count,multiplex_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "shaped-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prerequisite-tuning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on ...\n",
      "P01-P01 Control_1\n",
      "P03-P03 MTX1_72_PRS\n",
      "P05-P05 MTX10_72_PRS\n",
      "P07-P07 MTX100_72_PRS\n",
      "P09-P09 MTX200_72_PRS\n",
      "P02-P02 Control_2\n",
      "P04-P04 MTX1_96_PRS\n",
      "P06-P06 MTX10_96_PRS\n",
      "P08-P08 MTX100_96_PRS\n",
      "P10-P10 MTX200_96_PRS\n"
     ]
    }
   ],
   "source": [
    "# Organize dict of reads per strain\n",
    "count_2 =  norm.organize_data(count,db,multiplex_tag,\"PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "emerging-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating strains present in less than 90% of diploids\n",
    "count_3 = norm.absent(count_2,0.9,\"PCA\")\n",
    "\n",
    "count_sums = norm.get_sums(count_3,multiplex_tag,\"PCA\",db)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "preliminary-disclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control_1 \t\tBait: , (11 ORFs) 11 Prey, (9 ORFs) 9\n",
      "Control_2 \t\tBait: , (10 ORFs) 10 Prey, (9 ORFs) 9\n",
      "Generated : /Users/danyamamotoevans/GitHub/BFG/Data/test/normalization/Haploid_F.csv\n"
     ]
    }
   ],
   "source": [
    "# Normalize scores based on strain abundance of bait and prey haploids in Control condition\n",
    "\n",
    "raw_s,hap_s  = norm.compute_s(count_3,count_sums,db,multiplex_tag,\"PCA\")\n",
    "\n",
    "\n",
    "reps = norm.count_haploids(hap_s,norm_dir,db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "happy-westminster",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "count_haploids() missing 1 required positional argument: 'PCA_db'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a327add4dede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Organizing data and counting haploid strains\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreps\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_haploids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhap_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhaploid_replicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: count_haploids() missing 1 required positional argument: 'PCA_db'"
     ]
    }
   ],
   "source": [
    "# Organizing data and counting haploid strains\n",
    "reps= norm.count_haploids(hap_s,norm_dir,db)\n",
    "norm.haploid_replicates(reps,norm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize signal 's'\n",
    "## For Y2H ; Normalize data by Nth quantile of bait 'median distribution' of 's' score\n",
    "## For PCA ; Normalize data by median 's' score of both bait and prey \n",
    "\n",
    "normalized_score,hap_s = norm.compute_ds(raw_s,count_sums,db,multiplex_tag,\"PCA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(normalized_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.output_norm_score(normalized_score,db,norm_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
